{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 253680 entries, 0 to 253679\n",
      "Data columns (total 22 columns):\n",
      " #   Column                 Non-Null Count   Dtype\n",
      "---  ------                 --------------   -----\n",
      " 0   Diabetes               253680 non-null  int64\n",
      " 1   HighBP                 253680 non-null  int64\n",
      " 2   HighChol               253680 non-null  int64\n",
      " 3   BMI                    253680 non-null  int64\n",
      " 4   Smoker                 253680 non-null  int64\n",
      " 5   Stroke                 253680 non-null  int64\n",
      " 6   Myocardial             253680 non-null  int64\n",
      " 7   PhysActivity           253680 non-null  int64\n",
      " 8   Fruit                  253680 non-null  int64\n",
      " 9   Vegetables             253680 non-null  int64\n",
      " 10  HeavyDrinker           253680 non-null  int64\n",
      " 11  HasHealthcare          253680 non-null  int64\n",
      " 12  NotAbleToAffordDoctor  253680 non-null  int64\n",
      " 13  GeneralHealth          253680 non-null  int64\n",
      " 14  MentalHealth           253680 non-null  int64\n",
      " 15  PhysicalHealth         253680 non-null  int64\n",
      " 16  HardToClimbStairs      253680 non-null  int64\n",
      " 17  BiologicalSex          253680 non-null  int64\n",
      " 18  AgeBracket             253680 non-null  int64\n",
      " 19  EducationBracket       253680 non-null  int64\n",
      " 20  IncomeBracket          253680 non-null  int64\n",
      " 21  Zodiac                 253680 non-null  int64\n",
      "dtypes: int64(22)\n",
      "memory usage: 42.6 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "df = pd.read_csv(\"diabetes.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>Myocardial</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruit</th>\n",
       "      <th>Vegetables</th>\n",
       "      <th>HeavyDrinker</th>\n",
       "      <th>HasHealthcare</th>\n",
       "      <th>NotAbleToAffordDoctor</th>\n",
       "      <th>GeneralHealth</th>\n",
       "      <th>MentalHealth</th>\n",
       "      <th>PhysicalHealth</th>\n",
       "      <th>HardToClimbStairs</th>\n",
       "      <th>BiologicalSex</th>\n",
       "      <th>AgeBracket</th>\n",
       "      <th>EducationBracket</th>\n",
       "      <th>IncomeBracket</th>\n",
       "      <th>Zodiac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes  HighBP  HighChol  BMI  Smoker  Stroke  Myocardial  PhysActivity  \\\n",
       "0         0       1         1   40       1       0           0             0   \n",
       "1         0       0         0   25       1       0           0             1   \n",
       "2         0       1         1   28       0       0           0             0   \n",
       "3         0       1         0   27       0       0           0             1   \n",
       "4         0       1         1   24       0       0           0             1   \n",
       "\n",
       "   Fruit  Vegetables  HeavyDrinker  HasHealthcare  NotAbleToAffordDoctor  \\\n",
       "0      0           1             0              1                      0   \n",
       "1      0           0             0              0                      1   \n",
       "2      1           0             0              1                      1   \n",
       "3      1           1             0              1                      0   \n",
       "4      1           1             0              1                      0   \n",
       "\n",
       "   GeneralHealth  MentalHealth  PhysicalHealth  HardToClimbStairs  \\\n",
       "0              5            18              15                  1   \n",
       "1              3             0               0                  0   \n",
       "2              5            30              30                  1   \n",
       "3              2             0               0                  0   \n",
       "4              2             3               0                  0   \n",
       "\n",
       "   BiologicalSex  AgeBracket  EducationBracket  IncomeBracket  Zodiac  \n",
       "0              1           9                 4              3      10  \n",
       "1              1           7                 6              1      11  \n",
       "2              1           9                 4              8       2  \n",
       "3              1          11                 3              6      11  \n",
       "4              1          11                 5              4       8  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe does not have missing values\n"
     ]
    }
   ],
   "source": [
    "if df.isnull().any().any():\n",
    "    print('The dataframe has missing values')\n",
    "else:\n",
    "    print('The dataframe does not have missing values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "def logistic_regersion(X, y, random_state, name):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "    model = LogisticRegression(class_weight='balanced').fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    precision = metrics.precision_score(y_test, y_pred)\n",
    "    recall = metrics.recall_score(y_test, y_pred)\n",
    "    f1 = metrics.f1_score(y_test, y_pred)\n",
    "    if name !='':\n",
    "        print('After dropping ', name)\n",
    "    print(f'accuracy = {100 * accuracy:0.4f}%')\n",
    "    print(f'precision = {100 * precision:0.4f}%')\n",
    "    print(f'recall = {recall:0.4f}')\n",
    "    print(f'f1 = {f1:0.4f}')\n",
    "    y_prob = model.predict_proba(x_test)[:, 1]\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_prob)\n",
    "    auc_roc = metrics.auc(fpr, tpr)\n",
    "    print('*AUC is ', auc_roc)\n",
    "    print('') \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253680, 253680)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = ['HighBP', 'HighChol', 'BMI', 'Smoker','Stroke','Myocardial','PhysActivity','Fruit','Vegetables','HeavyDrinker','HasHealthcare','NotAbleToAffordDoctor','GeneralHealth','MentalHealth','PhysicalHealth','HardToClimbStairs', 'BiologicalSex', 'AgeBracket', 'EducationBracket', 'IncomeBracket', 'Zodiac']\n",
    "X = df[predictors]\n",
    "y = df['Diabetes']\n",
    "scaled = StandardScaler().fit_transform(X)\n",
    "scaled = pd.DataFrame(scaled, columns=X.columns)\n",
    "(len(X), len(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(202944, 202944)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "(len(x_train), len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 73.1690%\n",
      "precision = 31.7336%\n",
      "recall = 0.7712\n",
      "f1 = 0.4496\n",
      "*AUC is  0.8251768490461993\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping  HighBP\n",
      "accuracy = 72.0140%\n",
      "precision = 30.4870%\n",
      "recall = 0.7570\n",
      "f1 = 0.4347\n",
      "*AUC is  0.8127932618739113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping  HighChol\n",
      "accuracy = 72.0297%\n",
      "precision = 30.5506%\n",
      "recall = 0.7602\n",
      "f1 = 0.4359\n",
      "*AUC is  0.812742409384603\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping  BMI\n",
      "accuracy = 71.9765%\n",
      "precision = 30.4852%\n",
      "recall = 0.7590\n",
      "f1 = 0.4350\n",
      "*AUC is  0.8097925762948638\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping  Smoker\n",
      "accuracy = 72.5481%\n",
      "precision = 31.1416%\n",
      "recall = 0.7691\n",
      "f1 = 0.4433\n",
      "*AUC is  0.8184949823371992\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping  Stroke\n",
      "accuracy = 72.0928%\n",
      "precision = 30.7875%\n",
      "recall = 0.7720\n",
      "f1 = 0.4402\n",
      "*AUC is  0.8186495502634903\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping  Myocardial\n",
      "accuracy = 72.6190%\n",
      "precision = 31.3098%\n",
      "recall = 0.7760\n",
      "f1 = 0.4462\n",
      "*AUC is  0.8218826269872492\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping  PhysActivity\n",
      "accuracy = 72.3707%\n",
      "precision = 31.0654%\n",
      "recall = 0.7744\n",
      "f1 = 0.4434\n",
      "*AUC is  0.82112631867629\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping  Fruit\n",
      "accuracy = 72.2229%\n",
      "precision = 30.9553%\n",
      "recall = 0.7756\n",
      "f1 = 0.4425\n",
      "*AUC is  0.8208960734011659\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping  Vegetables\n",
      "accuracy = 72.5639%\n",
      "precision = 31.2399%\n",
      "recall = 0.7746\n",
      "f1 = 0.4452\n",
      "*AUC is  0.8214806659460134\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping  HeavyDrinker\n",
      "accuracy = 72.8299%\n",
      "precision = 31.3493%\n",
      "recall = 0.7662\n",
      "f1 = 0.4449\n",
      "*AUC is  0.8202993559762668\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping  HasHealthcare\n",
      "accuracy = 72.9561%\n",
      "precision = 31.5602%\n",
      "recall = 0.7726\n",
      "f1 = 0.4481\n",
      "*AUC is  0.8229931248536861\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping  NotAbleToAffordDoctor\n",
      "accuracy = 72.6210%\n",
      "precision = 31.2296%\n",
      "recall = 0.7706\n",
      "f1 = 0.4445\n",
      "*AUC is  0.8194928085091774\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping  GeneralHealth\n",
      "accuracy = 71.6355%\n",
      "precision = 30.0489%\n",
      "recall = 0.7498\n",
      "f1 = 0.4290\n",
      "*AUC is  0.8060630740689025\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping  MentalHealth\n",
      "accuracy = 72.4062%\n",
      "precision = 31.0796%\n",
      "recall = 0.7733\n",
      "f1 = 0.4434\n",
      "*AUC is  0.8202512069321625\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping  PhysicalHealth\n",
      "accuracy = 72.6683%\n",
      "precision = 31.3013%\n",
      "recall = 0.7726\n",
      "f1 = 0.4455\n",
      "*AUC is  0.8218875655141393\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping  HardToClimbStairs\n",
      "accuracy = 72.7373%\n",
      "precision = 31.2850%\n",
      "recall = 0.7674\n",
      "f1 = 0.4445\n",
      "*AUC is  0.8193180117395156\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping  BiologicalSex\n",
      "accuracy = 72.4101%\n",
      "precision = 31.0345%\n",
      "recall = 0.7701\n",
      "f1 = 0.4424\n",
      "*AUC is  0.819157052403585\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping  AgeBracket\n",
      "accuracy = 72.8694%\n",
      "precision = 31.2507%\n",
      "recall = 0.7575\n",
      "f1 = 0.4425\n",
      "*AUC is  0.8159578969872676\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping  EducationBracket\n",
      "accuracy = 72.6033%\n",
      "precision = 31.2244%\n",
      "recall = 0.7713\n",
      "f1 = 0.4445\n",
      "*AUC is  0.8214654138632893\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping  IncomeBracket\n",
      "accuracy = 72.4456%\n",
      "precision = 31.0932%\n",
      "recall = 0.7719\n",
      "f1 = 0.4433\n",
      "*AUC is  0.8187911856216223\n",
      "\n",
      "After dropping  Zodiac\n",
      "accuracy = 72.4732%\n",
      "precision = 31.1807%\n",
      "recall = 0.7760\n",
      "f1 = 0.4449\n",
      "*AUC is  0.8208049066017032\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model1 = logistic_regersion(scaled, y, 0, '')\n",
    "for i in range(len(predictors)):\n",
    "    temp = predictors[:]\n",
    "    temp.pop(i)\n",
    "    model2 = logistic_regersion(df[temp], y, 0,predictors[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Build a logistic regression model. Doing so: What is the best predictor of diabetes and what is the AUC of this model?\n",
    "\n",
    "I wrote a logistic regression function. I split data into training and testing sets and fitted the logistic regression with balanced class_weight. Finally, I computed evaluation metrics and the AUC. There are 22 columns including diabetes. I build 22 models, 1 with all predictors and 21 with 1 predictor dropped\n",
    "\n",
    "I put balanced for class_weight so that the parameter adjusts the weights of the different classes. The evaluation metrics and AUC evaluate the performance of a model.\n",
    "\n",
    "The data show that GeneralHealth is the best predictor, the reason is the AUC decreases the most when we drop GeneralHealth. The AUC decrease from 0.825 to 0.806(the lowest among the 21 models)\n",
    "\n",
    "I believe the findings mean that the dropped column is important in predicting the target variable. Maybe it has the strongest correlation between the predictor and the target variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "\n",
    "def svm_classification(X, y, random_state, name):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "    model = LinearSVC(dual=False, class_weight='balanced', random_state=0).fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    precision = metrics.precision_score(y_test, y_pred)\n",
    "    recall = metrics.recall_score(y_test, y_pred)\n",
    "    f1 = metrics.f1_score(y_test, y_pred)\n",
    "    if name != '':\n",
    "        print(f'After dropping {name}:')\n",
    "    print(f'accuracy = {100 * accuracy:.4f}%')\n",
    "    print(f'precision = {100 * precision:.4f}%')\n",
    "    print(f'recall = {recall:.4f}')\n",
    "    print(f'f1 = {f1:.4f}')\n",
    "    y_prob = model.decision_function(x_test)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_prob)\n",
    "    auc_roc = metrics.auc(fpr, tpr)\n",
    "    print(f'*AUC is {auc_roc:.4f}')\n",
    "    print('')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 72.7255%\n",
      "precision = 31.4047%\n",
      "recall = 0.7760\n",
      "f1 = 0.4471\n",
      "*AUC is 0.8249\n",
      "\n",
      "After dropping HighBP:\n",
      "accuracy = 72.6624%\n",
      "precision = 31.1285%\n",
      "recall = 0.7616\n",
      "f1 = 0.4419\n",
      "*AUC is 0.8176\n",
      "\n",
      "After dropping HighChol:\n",
      "accuracy = 72.4417%\n",
      "precision = 31.0601%\n",
      "recall = 0.7699\n",
      "f1 = 0.4426\n",
      "*AUC is 0.8190\n",
      "\n",
      "After dropping BMI:\n",
      "accuracy = 71.6651%\n",
      "precision = 30.2845%\n",
      "recall = 0.7631\n",
      "f1 = 0.4336\n",
      "*AUC is 0.8101\n",
      "\n",
      "After dropping Smoker:\n",
      "accuracy = 72.7531%\n",
      "precision = 31.4398%\n",
      "recall = 0.7767\n",
      "f1 = 0.4476\n",
      "*AUC is 0.8249\n",
      "\n",
      "After dropping Stroke:\n",
      "accuracy = 72.6979%\n",
      "precision = 31.3717%\n",
      "recall = 0.7755\n",
      "f1 = 0.4467\n",
      "*AUC is 0.8246\n",
      "\n",
      "After dropping Myocardial:\n",
      "accuracy = 72.4732%\n",
      "precision = 31.2079%\n",
      "recall = 0.7778\n",
      "f1 = 0.4454\n",
      "*AUC is 0.8242\n",
      "\n",
      "After dropping PhysActivity:\n",
      "accuracy = 72.7235%\n",
      "precision = 31.4050%\n",
      "recall = 0.7762\n",
      "f1 = 0.4472\n",
      "*AUC is 0.8248\n",
      "\n",
      "After dropping Fruit:\n",
      "accuracy = 72.7294%\n",
      "precision = 31.4040%\n",
      "recall = 0.7758\n",
      "f1 = 0.4471\n",
      "*AUC is 0.8249\n",
      "\n",
      "After dropping Vegetables:\n",
      "accuracy = 72.7393%\n",
      "precision = 31.4149%\n",
      "recall = 0.7759\n",
      "f1 = 0.4472\n",
      "*AUC is 0.8248\n",
      "\n",
      "After dropping HeavyDrinker:\n",
      "accuracy = 72.6979%\n",
      "precision = 31.3738%\n",
      "recall = 0.7756\n",
      "f1 = 0.4468\n",
      "*AUC is 0.8237\n",
      "\n",
      "After dropping HasHealthcare:\n",
      "accuracy = 72.7097%\n",
      "precision = 31.3885%\n",
      "recall = 0.7759\n",
      "f1 = 0.4470\n",
      "*AUC is 0.8248\n",
      "\n",
      "After dropping NotAbleToAffordDoctor:\n",
      "accuracy = 72.7334%\n",
      "precision = 31.4096%\n",
      "recall = 0.7759\n",
      "f1 = 0.4472\n",
      "*AUC is 0.8249\n",
      "\n",
      "After dropping GeneralHealth:\n",
      "accuracy = 71.5764%\n",
      "precision = 30.1465%\n",
      "recall = 0.7591\n",
      "f1 = 0.4316\n",
      "*AUC is 0.8096\n",
      "\n",
      "After dropping MentalHealth:\n",
      "accuracy = 72.7412%\n",
      "precision = 31.4375%\n",
      "recall = 0.7773\n",
      "f1 = 0.4477\n",
      "*AUC is 0.8248\n",
      "\n",
      "After dropping PhysicalHealth:\n",
      "accuracy = 72.7275%\n",
      "precision = 31.3835%\n",
      "recall = 0.7745\n",
      "f1 = 0.4467\n",
      "*AUC is 0.8247\n",
      "\n",
      "After dropping HardToClimbStairs:\n",
      "accuracy = 72.6447%\n",
      "precision = 31.3430%\n",
      "recall = 0.7767\n",
      "f1 = 0.4466\n",
      "*AUC is 0.8247\n",
      "\n",
      "After dropping BiologicalSex:\n",
      "accuracy = 72.6171%\n",
      "precision = 31.2703%\n",
      "recall = 0.7735\n",
      "f1 = 0.4454\n",
      "*AUC is 0.8239\n",
      "\n",
      "After dropping AgeBracket:\n",
      "accuracy = 72.8457%\n",
      "precision = 31.1819%\n",
      "recall = 0.7544\n",
      "f1 = 0.4413\n",
      "*AUC is 0.8169\n",
      "\n",
      "After dropping EducationBracket:\n",
      "accuracy = 72.7728%\n",
      "precision = 31.4387%\n",
      "recall = 0.7755\n",
      "f1 = 0.4474\n",
      "*AUC is 0.8248\n",
      "\n",
      "After dropping IncomeBracket:\n",
      "accuracy = 72.6289%\n",
      "precision = 31.3290%\n",
      "recall = 0.7767\n",
      "f1 = 0.4465\n",
      "*AUC is 0.8242\n",
      "\n",
      "After dropping Zodiac:\n",
      "accuracy = 72.7255%\n",
      "precision = 31.4026%\n",
      "recall = 0.7759\n",
      "f1 = 0.4471\n",
      "*AUC is 0.8249\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model1 = svm_classification(scaled, y, 0, '')\n",
    "for i in range(len(predictors)):\n",
    "    temp = predictors[:]\n",
    "    temp.pop(i)\n",
    "    model2 = svm_classification(df[temp], y, 0,predictors[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Build a SVM. Doing so: What is the best predictor of diabetes and what is the AUC of this model?\n",
    "\n",
    "I wrote a svm_classification function. In the function, I split data into training and testing sets and fitted the LinearSVC with balanced class_weight and False for dual. Finally, I computed evaluation metrics and the AUC. There are 22 columns including diabetes. I build 22 models, 1 with all predictors and 21 with 1 predictor dropped\n",
    "\n",
    "I put balanced for class_weight so that the parameter adjusts the weights of the different classes and False to dual to tell the algorithm to solve the primal optimization problem. The evaluation metrics and AUC evaluate the performance of a model.\n",
    "\n",
    "Based on the data, it has been observed that GeneralHealth is the most significant predictor, as it leads to the highest decrease in AUC when dropped. The AUC drops from 0.8249 to 0.8096, which is the lowest among all 21 models. \n",
    "\n",
    "These findings suggest that GeneralHealth is a crucial factor in predicting the target variable in SVM model, possibly due to its strong correlation with the predictor variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': 10, 'max_leaf_nodes': 20, 'min_samples_split': 2}\n",
      "Best cross-validation score: 0.8654308542398607\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "param_grid = {\n",
    "    'criterion': ['entropy', 'gini'],\n",
    "    'max_depth': [2, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'max_leaf_nodes': [5, 10, 20, 50]\n",
    "}\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "print('Best hyperparameters:', grid_search.best_params_)\n",
    "print('Best cross-validation score:', grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def decision_tree_classification(X, y, random_state, name):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "    model = DecisionTreeClassifier(criterion='gini', class_weight = 'balanced', max_features=1.0, max_leaf_nodes=20).fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    precision = metrics.precision_score(y_test, y_pred)\n",
    "    recall = metrics.recall_score(y_test, y_pred)\n",
    "    f1 = metrics.f1_score(y_test, y_pred)\n",
    "    if name != '':\n",
    "        print(f'After dropping {name}:')\n",
    "    print(f'accuracy = {100 * accuracy:.4f}%')\n",
    "    print(f'precision = {100 * precision:.4f}%')\n",
    "    print(f'recall = {recall:.4f}')\n",
    "    print(f'f1 = {f1:.4f}')\n",
    "    # Compute AUC-ROC\n",
    "    y_prob = model.predict_proba(x_test)[:, 1]\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_prob)\n",
    "    auc_roc = metrics.auc(fpr, tpr)\n",
    "    print(f'*AUC is {auc_roc:.4f}')\n",
    "    print('')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 72.4377%\n",
      "precision = 30.8011%\n",
      "recall = 0.7534\n",
      "f1 = 0.4373\n",
      "*AUC is 0.8045\n",
      "\n",
      "After dropping HighBP:\n",
      "accuracy = 65.9768%\n",
      "precision = 27.0347%\n",
      "recall = 0.8204\n",
      "f1 = 0.4067\n",
      "*AUC is 0.7990\n",
      "\n",
      "After dropping HighChol:\n",
      "accuracy = 72.4377%\n",
      "precision = 30.8011%\n",
      "recall = 0.7534\n",
      "f1 = 0.4373\n",
      "*AUC is 0.8043\n",
      "\n",
      "After dropping BMI:\n",
      "accuracy = 65.8034%\n",
      "precision = 26.8400%\n",
      "recall = 0.8147\n",
      "f1 = 0.4038\n",
      "*AUC is 0.7985\n",
      "\n",
      "After dropping Smoker:\n",
      "accuracy = 72.4377%\n",
      "precision = 30.8011%\n",
      "recall = 0.7534\n",
      "f1 = 0.4373\n",
      "*AUC is 0.8045\n",
      "\n",
      "After dropping Stroke:\n",
      "accuracy = 72.4377%\n",
      "precision = 30.8011%\n",
      "recall = 0.7534\n",
      "f1 = 0.4373\n",
      "*AUC is 0.8045\n",
      "\n",
      "After dropping Myocardial:\n",
      "accuracy = 72.4377%\n",
      "precision = 30.8011%\n",
      "recall = 0.7534\n",
      "f1 = 0.4373\n",
      "*AUC is 0.8045\n",
      "\n",
      "After dropping PhysActivity:\n",
      "accuracy = 72.4377%\n",
      "precision = 30.8011%\n",
      "recall = 0.7534\n",
      "f1 = 0.4373\n",
      "*AUC is 0.8045\n",
      "\n",
      "After dropping Fruit:\n",
      "accuracy = 72.4377%\n",
      "precision = 30.8011%\n",
      "recall = 0.7534\n",
      "f1 = 0.4373\n",
      "*AUC is 0.8045\n",
      "\n",
      "After dropping Vegetables:\n",
      "accuracy = 72.4377%\n",
      "precision = 30.8011%\n",
      "recall = 0.7534\n",
      "f1 = 0.4373\n",
      "*AUC is 0.8045\n",
      "\n",
      "After dropping HeavyDrinker:\n",
      "accuracy = 72.4377%\n",
      "precision = 30.8011%\n",
      "recall = 0.7534\n",
      "f1 = 0.4373\n",
      "*AUC is 0.8045\n",
      "\n",
      "After dropping HasHealthcare:\n",
      "accuracy = 72.4377%\n",
      "precision = 30.8011%\n",
      "recall = 0.7534\n",
      "f1 = 0.4373\n",
      "*AUC is 0.8045\n",
      "\n",
      "After dropping NotAbleToAffordDoctor:\n",
      "accuracy = 72.4377%\n",
      "precision = 30.8011%\n",
      "recall = 0.7534\n",
      "f1 = 0.4373\n",
      "*AUC is 0.8045\n",
      "\n",
      "After dropping GeneralHealth:\n",
      "accuracy = 68.8880%\n",
      "precision = 27.9498%\n",
      "recall = 0.7536\n",
      "f1 = 0.4078\n",
      "*AUC is 0.7874\n",
      "\n",
      "After dropping MentalHealth:\n",
      "accuracy = 72.4377%\n",
      "precision = 30.8011%\n",
      "recall = 0.7534\n",
      "f1 = 0.4373\n",
      "*AUC is 0.8045\n",
      "\n",
      "After dropping PhysicalHealth:\n",
      "accuracy = 72.4377%\n",
      "precision = 30.8011%\n",
      "recall = 0.7534\n",
      "f1 = 0.4373\n",
      "*AUC is 0.8045\n",
      "\n",
      "After dropping HardToClimbStairs:\n",
      "accuracy = 72.4377%\n",
      "precision = 30.8011%\n",
      "recall = 0.7534\n",
      "f1 = 0.4373\n",
      "*AUC is 0.8045\n",
      "\n",
      "After dropping BiologicalSex:\n",
      "accuracy = 72.4377%\n",
      "precision = 30.8011%\n",
      "recall = 0.7534\n",
      "f1 = 0.4373\n",
      "*AUC is 0.8045\n",
      "\n",
      "After dropping AgeBracket:\n",
      "accuracy = 71.4305%\n",
      "precision = 30.0613%\n",
      "recall = 0.7615\n",
      "f1 = 0.4311\n",
      "*AUC is 0.8009\n",
      "\n",
      "After dropping EducationBracket:\n",
      "accuracy = 72.4377%\n",
      "precision = 30.8011%\n",
      "recall = 0.7534\n",
      "f1 = 0.4373\n",
      "*AUC is 0.8045\n",
      "\n",
      "After dropping IncomeBracket:\n",
      "accuracy = 72.4377%\n",
      "precision = 30.8011%\n",
      "recall = 0.7534\n",
      "f1 = 0.4373\n",
      "*AUC is 0.8045\n",
      "\n",
      "After dropping Zodiac:\n",
      "accuracy = 72.4377%\n",
      "precision = 30.8011%\n",
      "recall = 0.7534\n",
      "f1 = 0.4373\n",
      "*AUC is 0.8045\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model1 = decision_tree_classification(scaled, y, 0, '')\n",
    "for i in range(len(predictors)):\n",
    "    temp = predictors[:]\n",
    "    temp.pop(i)\n",
    "    model2 = decision_tree_classification(df[temp], y, 0,predictors[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Use a single, individual decision tree. Doing so: What is the best predictor of diabetes and what is the AUC of this model?\n",
    "\n",
    "I utilized GridSearchCV to find the best parameters for the model to fit the data. After collecting the parameters, I wrote a decision_tree_classification function. In the function, I split data into training and testing sets and fitted the DecisionTreeClassifier with balanced class_weight, gini criterion, max_features=1.0 and max_leaf_nodes=20. Finally, I computed evaluation metrics and the AUC. There are 22 columns including diabetes. I build 22 models, 1 with all predictors and 21 with 1 predictor dropped\n",
    "\n",
    "I put balanced for class_weight so that the parameter adjusts the weights of the different classes and False to dual to tell the algorithm to solve the primal optimization problem. Set a number for max_features and max_leaf_nodes controls the complexity of the decision tree and can help prevent overfitting. The evaluation metrics and AUC evaluate the performance of a model.\n",
    "\n",
    "According to the data, the most notable predictor is GeneralHealth, as removing this predictor leads to the largest reduction in AUC among all 21 models tested. Specifically, the AUC value decreases from 0.8045 to 0.7874, which is the lowest observed in the model.\n",
    "\n",
    "These findings indicate that GeneralHealth plays a crucial role in predicting the target variable in the decision tree model, likely due to its high correlation with the predictor variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "2160 fits failed out of a total of 4320.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2160 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 397, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `max_sample` cannot be set if `bootstrap=False`. Either switch to `bootstrap=True` or set `max_sample=None`.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.8613657  0.8613657  0.8613657  0.8613657  0.8613657  0.8613657\n",
      " 0.8613657  0.8613657  0.8613657  0.8613657  0.8613657  0.8613657\n",
      " 0.8613657  0.8613657  0.8613657  0.8613657  0.8613657  0.8613657\n",
      " 0.8613657  0.8613657  0.8613657  0.8613657  0.8613657  0.8613657\n",
      " 0.8613657  0.8613657  0.8613657  0.8613657  0.8613657  0.8613657\n",
      " 0.8613657  0.8613657  0.8613657  0.8613657  0.8613657  0.8613657\n",
      " 0.8613657  0.8613657  0.8613657  0.8613657  0.8613657  0.8613657\n",
      " 0.8613657  0.8613657  0.8613657  0.8613657  0.8613657  0.8613657\n",
      " 0.8613657  0.8613657  0.8613657  0.8613657  0.8613657  0.8613657\n",
      " 0.8613657  0.8613657  0.8613657  0.8613657  0.8613657  0.8613657\n",
      " 0.8613657  0.8613657  0.8613657  0.8613657  0.8613657  0.8613657\n",
      " 0.8613657  0.8613657  0.8613657  0.8613657  0.8613657  0.8613657\n",
      " 0.86246453 0.86246945 0.86209989 0.86244481 0.86206047 0.8618141\n",
      " 0.86193729 0.86178946 0.8614741  0.86216887 0.86238075 0.86208511\n",
      " 0.86242017 0.86210482 0.86178946 0.86198656 0.86163178 0.86158251\n",
      " 0.86172048 0.86173526 0.86154801 0.86178946 0.86174018 0.86150367\n",
      " 0.86162685 0.86154801 0.86159236 0.86161207 0.861617   0.86157758\n",
      " 0.8618141  0.86164164 0.86148396 0.86202598 0.86172048 0.86163671\n",
      " 0.86236598 0.86210482 0.86186337 0.8629277  0.86213931 0.86200627\n",
      " 0.86211467 0.86178453 0.8615283  0.86228221 0.8621196  0.86193236\n",
      " 0.86234626 0.86182888 0.86214424 0.86202598 0.86175497 0.86154801\n",
      " 0.8619225  0.86151352 0.86157758 0.86178453 0.86160222 0.8615283\n",
      " 0.8621196  0.86151352 0.86157265 0.86187815 0.86169091 0.86162685\n",
      " 0.86188308 0.86149874 0.86157758 0.86141497 0.8615628  0.8615628\n",
      " 0.86069062 0.8646671  0.86526332 0.86264191 0.86472623 0.86471637\n",
      " 0.8628735  0.86246452 0.86266162 0.8633761  0.86455377 0.86439609\n",
      " 0.86296712 0.86435667 0.8646671  0.86252365 0.8626222  0.86261234\n",
      " 0.86570187 0.86583984 0.865761   0.86547028 0.86573636 0.8658152\n",
      " 0.8653126  0.865761   0.86585955 0.86548506 0.86577578 0.86579549\n",
      " 0.86524361 0.86567723 0.86584476 0.8655639  0.86546535 0.86566245\n",
      " 0.86088773 0.86505144 0.86495782 0.86274538 0.8648642  0.86483956\n",
      " 0.86346479 0.86254829 0.86250887 0.8630361  0.8645784  0.86470159\n",
      " 0.86342538 0.86449956 0.86463753 0.86285872 0.86260249 0.86253844\n",
      " 0.8655836  0.86583984 0.8656723  0.8651697  0.86577578 0.86584476\n",
      " 0.86575607 0.86584969 0.86591375 0.86504651 0.86562795 0.86560332\n",
      " 0.86539144 0.86559839 0.86552941 0.86550969 0.86572158 0.8656723\n",
      " 0.8613657  0.8613657  0.8613657  0.8613657  0.8613657  0.8613657\n",
      " 0.8613657  0.8613657  0.8613657  0.8613657  0.8613657  0.8613657\n",
      " 0.8613657  0.8613657  0.8613657  0.8613657  0.8613657  0.8613657\n",
      " 0.8613657  0.8613657  0.8613657  0.8613657  0.8613657  0.8613657\n",
      " 0.8613657  0.8613657  0.8613657  0.8613657  0.8613657  0.8613657\n",
      " 0.8613657  0.8613657  0.8613657  0.8613657  0.8613657  0.8613657\n",
      " 0.8613657  0.8613657  0.8613657  0.8613657  0.8613657  0.8613657\n",
      " 0.8613657  0.8613657  0.8613657  0.8613657  0.8613657  0.8613657\n",
      " 0.8613657  0.8613657  0.8613657  0.8613657  0.8613657  0.8613657\n",
      " 0.8613657  0.8613657  0.8613657  0.8613657  0.8613657  0.8613657\n",
      " 0.8613657  0.8613657  0.8613657  0.8613657  0.8613657  0.8613657\n",
      " 0.8613657  0.8613657  0.8613657  0.8613657  0.8613657  0.8613657\n",
      " 0.86254336 0.86289814 0.86234626 0.86311988 0.86205062 0.86243003\n",
      " 0.86214424 0.86187815 0.86182395 0.86280945 0.86270104 0.86229699\n",
      " 0.86264684 0.86222308 0.86227728 0.86186337 0.86187815 0.86172047\n",
      " 0.86199149 0.86204569 0.86207525 0.8622822  0.86182888 0.86190279\n",
      " 0.86248916 0.86201612 0.86190279 0.86210974 0.86199149 0.86212453\n",
      " 0.86179439 0.86208511 0.86190772 0.86230192 0.86192743 0.86181902\n",
      " 0.86224771 0.86253351 0.86242017 0.86266654 0.86235119 0.86214916\n",
      " 0.86237583 0.86177468 0.86180917 0.86290307 0.86232655 0.86233148\n",
      " 0.86262713 0.86216887 0.86230191 0.86207525 0.86214424 0.86173526\n",
      " 0.86221815 0.8621738  0.86197178 0.86216394 0.86211467 0.86204076\n",
      " 0.86179931 0.86207525 0.8620309  0.86243496 0.86190279 0.86201119\n",
      " 0.86204076 0.86216888 0.86193728 0.86182395 0.8620654  0.86185844\n",
      " 0.86042947 0.86494304 0.8651697  0.86251872 0.86485434 0.86504159\n",
      " 0.86313466 0.86283901 0.86264191 0.8637161  0.86477057 0.86464739\n",
      " 0.86311988 0.86427784 0.86476072 0.86291293 0.86304596 0.86261235\n",
      " 0.86553926 0.86597781 0.86594331 0.86574621 0.86585462 0.86609114\n",
      " 0.86555897 0.86597781 0.86603693 0.86539143 0.86569694 0.866032\n",
      " 0.86544564 0.86603694 0.86599259 0.86588418 0.86576592 0.86593839\n",
      " 0.8604886  0.86417928 0.86492333 0.86220829 0.86486419 0.86496275\n",
      " 0.86295234 0.86286365 0.86282423 0.86272567 0.8643616  0.86469174\n",
      " 0.86319378 0.86422363 0.86424826 0.86233148 0.86241032 0.86288336\n",
      " 0.86554911 0.86592853 0.86605664 0.86542593 0.86602708 0.86603693\n",
      " 0.86559839 0.86594331 0.86590389 0.86524362 0.86584969 0.86589896\n",
      " 0.86559839 0.8660123  0.86583491 0.86526825 0.86598273 0.86580534\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'bootstrap': True, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'max_samples': 1.0, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Best cross-validation score: 0.8660911357825739\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "param_grid = {\n",
    "    'criterion': ['entropy', 'gini'],\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_samples': [ 0.01, 1.0],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap':[True, False],\n",
    "    'max_depth': [2, 5, 10],\n",
    "    'min_samples_split': [2, 10, 50],\n",
    "    'min_samples_leaf': [1, 4]\n",
    "}\n",
    "dt = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "print('Best hyperparameters:', grid_search.best_params_)\n",
    "print('Best cross-validation score:', grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def random_forest_classification(X, y, random_state, name):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "    model = RandomForestClassifier(n_estimators=50, max_samples=1.0,bootstrap=True, criterion='gini', max_depth=10, max_features = 'sqrt', min_samples_leaf = 1,min_samples_split = 2).fit(x_train, y_train)#max_leaf_nodes min_sample_leaf\n",
    "    y_pred = model.predict(x_test)\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    precision = metrics.precision_score(y_test, y_pred)\n",
    "    recall = metrics.recall_score(y_test, y_pred)\n",
    "    f1 = metrics.f1_score(y_test, y_pred)\n",
    "    if name != '':\n",
    "        print(f'After dropping {name}:')\n",
    "    print(f'accuracy = {100 * accuracy:.4f}%')\n",
    "    print(f'precision = {100 * precision:.4f}%')\n",
    "    print(f'recall = {recall:.4f}')\n",
    "    print(f'f1 = {f1:.4f}')\n",
    "    y_prob = model.predict_proba(x_test)[:, 1]\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_prob)\n",
    "    auc_roc = metrics.auc(fpr, tpr)\n",
    "    print(f'*AUC is {auc_roc:.4f}')\n",
    "    print('')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 86.3273%\n",
      "precision = 63.9796%\n",
      "recall = 0.0870\n",
      "f1 = 0.1531\n",
      "*AUC is 0.8288\n",
      "\n",
      "After dropping HighBP:\n",
      "accuracy = 86.2800%\n",
      "precision = 64.0449%\n",
      "recall = 0.0790\n",
      "f1 = 0.1407\n",
      "*AUC is 0.8229\n",
      "\n",
      "After dropping HighChol:\n",
      "accuracy = 86.2228%\n",
      "precision = 64.6358%\n",
      "recall = 0.0677\n",
      "f1 = 0.1225\n",
      "*AUC is 0.8233\n",
      "\n",
      "After dropping BMI:\n",
      "accuracy = 85.9646%\n",
      "precision = 62.5698%\n",
      "recall = 0.0311\n",
      "f1 = 0.0592\n",
      "*AUC is 0.8152\n",
      "\n",
      "After dropping Smoker:\n",
      "accuracy = 86.3371%\n",
      "precision = 63.9083%\n",
      "recall = 0.0889\n",
      "f1 = 0.1561\n",
      "*AUC is 0.8285\n",
      "\n",
      "After dropping Stroke:\n",
      "accuracy = 86.3726%\n",
      "precision = 63.8140%\n",
      "recall = 0.0951\n",
      "f1 = 0.1656\n",
      "*AUC is 0.8287\n",
      "\n",
      "After dropping Myocardial:\n",
      "accuracy = 86.3016%\n",
      "precision = 63.6364%\n",
      "recall = 0.0845\n",
      "f1 = 0.1491\n",
      "*AUC is 0.8289\n",
      "\n",
      "After dropping PhysActivity:\n",
      "accuracy = 86.3746%\n",
      "precision = 64.1098%\n",
      "recall = 0.0939\n",
      "f1 = 0.1638\n",
      "*AUC is 0.8288\n",
      "\n",
      "After dropping Fruit:\n",
      "accuracy = 86.3312%\n",
      "precision = 63.3981%\n",
      "recall = 0.0906\n",
      "f1 = 0.1585\n",
      "*AUC is 0.8292\n",
      "\n",
      "After dropping Vegetables:\n",
      "accuracy = 86.4041%\n",
      "precision = 64.3974%\n",
      "recall = 0.0971\n",
      "f1 = 0.1687\n",
      "*AUC is 0.8286\n",
      "\n",
      "After dropping HeavyDrinker:\n",
      "accuracy = 86.3884%\n",
      "precision = 64.5654%\n",
      "recall = 0.0937\n",
      "f1 = 0.1637\n",
      "*AUC is 0.8278\n",
      "\n",
      "After dropping HasHealthcare:\n",
      "accuracy = 86.3430%\n",
      "precision = 64.4764%\n",
      "recall = 0.0871\n",
      "f1 = 0.1535\n",
      "*AUC is 0.8287\n",
      "\n",
      "After dropping NotAbleToAffordDoctor:\n",
      "accuracy = 86.3667%\n",
      "precision = 64.7295%\n",
      "recall = 0.0896\n",
      "f1 = 0.1574\n",
      "*AUC is 0.8289\n",
      "\n",
      "After dropping GeneralHealth:\n",
      "accuracy = 86.3135%\n",
      "precision = 64.6221%\n",
      "recall = 0.0818\n",
      "f1 = 0.1452\n",
      "*AUC is 0.8138\n",
      "\n",
      "After dropping MentalHealth:\n",
      "accuracy = 86.3825%\n",
      "precision = 63.9042%\n",
      "recall = 0.0962\n",
      "f1 = 0.1673\n",
      "*AUC is 0.8283\n",
      "\n",
      "After dropping PhysicalHealth:\n",
      "accuracy = 86.3194%\n",
      "precision = 64.0041%\n",
      "recall = 0.0856\n",
      "f1 = 0.1509\n",
      "*AUC is 0.8289\n",
      "\n",
      "After dropping HardToClimbStairs:\n",
      "accuracy = 86.3864%\n",
      "precision = 64.8728%\n",
      "recall = 0.0919\n",
      "f1 = 0.1611\n",
      "*AUC is 0.8294\n",
      "\n",
      "After dropping BiologicalSex:\n",
      "accuracy = 86.4002%\n",
      "precision = 64.8236%\n",
      "recall = 0.0943\n",
      "f1 = 0.1646\n",
      "*AUC is 0.8283\n",
      "\n",
      "After dropping AgeBracket:\n",
      "accuracy = 86.3292%\n",
      "precision = 63.5468%\n",
      "recall = 0.0894\n",
      "f1 = 0.1568\n",
      "*AUC is 0.8199\n",
      "\n",
      "After dropping EducationBracket:\n",
      "accuracy = 86.3962%\n",
      "precision = 64.8987%\n",
      "recall = 0.0933\n",
      "f1 = 0.1632\n",
      "*AUC is 0.8294\n",
      "\n",
      "After dropping IncomeBracket:\n",
      "accuracy = 86.3765%\n",
      "precision = 63.7788%\n",
      "recall = 0.0960\n",
      "f1 = 0.1668\n",
      "*AUC is 0.8278\n",
      "\n",
      "After dropping Zodiac:\n",
      "accuracy = 86.3884%\n",
      "precision = 64.1597%\n",
      "recall = 0.0958\n",
      "f1 = 0.1667\n",
      "*AUC is 0.8289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model1 = random_forest_classification(scaled, y, 0, '')\n",
    "for i in range(len(predictors)):\n",
    "    temp = predictors[:]\n",
    "    temp.pop(i)\n",
    "    model2 = random_forest_classification(df[temp], y, 0,predictors[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Build a random forest model. Doing so: What is the best predictor of diabetes and what is the AUC of this model?\n",
    "\n",
    "I also utilized GridSearchCV to find the best parameters for the model to fit the data. After collecting the parameters, I wrote a random_forest_classification function. In the function, I split data into training and testing sets and fitted the RandomForestClassifier with balanced class_weight, gini criterion, True to bootstrap, max_leaf_nodes=20, n_estimators=50, max_samples=1.0, max_depth=10, max_features = 'sqrt', min_samples_leaf = 1 and min_samples_split = 2. Finally, I computed evaluation metrics and the AUC. There are 22 columns including diabetes. I build 22 models, 1 with all predictors and 21 with 1 predictor dropped\n",
    "\n",
    "Balanced class_weight was chosen to adjust the weights of different classes, while the number of max_features, min_samples_split, min_samples_leaf, max_leaf_nodes, and n_estimators were set to control decision tree complexity and prevent overfitting. Evaluation metrics and AUC were utilized to assess the model's performance.\n",
    "\n",
    "The results showed that GeneralHealth was the most significant predictor, as removing it led to the largest reduction in AUC among all 21 models tested. Specifically, the AUC value decreases from 0.8289 to 0.8143, which is the lowest observed in the model.\n",
    "\n",
    "This indicates that GeneralHealth plays a crucial role in predicting the target variable, likely due to its high correlation with the predictor variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'algorithm': 'SAMME.R', 'learning_rate': 1, 'n_estimators': 200}\n",
      "Best score: 0.8256\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "base_estimator = DecisionTreeClassifier(max_depth=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'algorithm': ['SAMME', 'SAMME.R']\n",
    "}\n",
    "ada = AdaBoostClassifier(estimator=base_estimator)\n",
    "grid_search = GridSearchCV(estimator=ada, param_grid=param_grid, cv=5, scoring='roc_auc')\n",
    "grid_search.fit(X, y)\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best score: {grid_search.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def adaboost_classification(X, y, random_state, name):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "    bdt = AdaBoostClassifier(\n",
    "        DecisionTreeClassifier(criterion='gini', class_weight = 'balanced', max_features=1.0, max_leaf_nodes=20), algorithm=\"SAMME.R\", n_estimators=200, learning_rate=0.1\n",
    "    )\n",
    "    model = bdt.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    precision = metrics.precision_score(y_test, y_pred)\n",
    "    recall = metrics.recall_score(y_test, y_pred)\n",
    "    f1 = metrics.f1_score(y_test, y_pred)\n",
    "    if name != '':\n",
    "        print(f'After dropping {name}:')\n",
    "    print(f'accuracy = {100 * accuracy:.4f}%')\n",
    "    print(f'precision = {100 * precision:.4f}%')\n",
    "    print(f'recall = {recall:.4f}')\n",
    "    print(f'f1 = {f1:.4f}')\n",
    "    y_prob = model.predict_proba(x_test)[:, 1]\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_prob)\n",
    "    auc_roc = metrics.auc(fpr, tpr)\n",
    "    print(f'*AUC is {auc_roc:.4f}')\n",
    "    print('')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 71.6809%\n",
      "precision = 30.7928%\n",
      "recall = 0.7956\n",
      "f1 = 0.4440\n",
      "*AUC is 0.8231\n",
      "\n",
      "After dropping HighBP:\n",
      "accuracy = 70.9910%\n",
      "precision = 30.2208%\n",
      "recall = 0.7953\n",
      "f1 = 0.4380\n",
      "*AUC is 0.8197\n",
      "\n",
      "After dropping HighChol:\n",
      "accuracy = 71.2295%\n",
      "precision = 30.3960%\n",
      "recall = 0.7941\n",
      "f1 = 0.4396\n",
      "*AUC is 0.8197\n",
      "\n",
      "After dropping BMI:\n",
      "accuracy = 70.0666%\n",
      "precision = 29.4624%\n",
      "recall = 0.7934\n",
      "f1 = 0.4297\n",
      "*AUC is 0.8125\n",
      "\n",
      "After dropping Smoker:\n",
      "accuracy = 71.7577%\n",
      "precision = 30.8574%\n",
      "recall = 0.7956\n",
      "f1 = 0.4447\n",
      "*AUC is 0.8248\n",
      "\n",
      "After dropping Stroke:\n",
      "accuracy = 71.7420%\n",
      "precision = 30.8379%\n",
      "recall = 0.7952\n",
      "f1 = 0.4444\n",
      "*AUC is 0.8234\n",
      "\n",
      "After dropping Myocardial:\n",
      "accuracy = 71.5725%\n",
      "precision = 30.7207%\n",
      "recall = 0.7968\n",
      "f1 = 0.4434\n",
      "*AUC is 0.8217\n",
      "\n",
      "After dropping PhysActivity:\n",
      "accuracy = 71.5843%\n",
      "precision = 30.7037%\n",
      "recall = 0.7950\n",
      "f1 = 0.4430\n",
      "*AUC is 0.8229\n",
      "\n",
      "After dropping Fruit:\n",
      "accuracy = 71.5725%\n",
      "precision = 30.7434%\n",
      "recall = 0.7984\n",
      "f1 = 0.4439\n",
      "*AUC is 0.8248\n",
      "\n",
      "After dropping Vegetables:\n",
      "accuracy = 71.6907%\n",
      "precision = 30.8729%\n",
      "recall = 0.8004\n",
      "f1 = 0.4456\n",
      "*AUC is 0.8253\n",
      "\n",
      "After dropping HeavyDrinker:\n",
      "accuracy = 71.5941%\n",
      "precision = 30.7181%\n",
      "recall = 0.7955\n",
      "f1 = 0.4432\n",
      "*AUC is 0.8230\n",
      "\n",
      "After dropping HasHealthcare:\n",
      "accuracy = 71.6572%\n",
      "precision = 30.8510%\n",
      "recall = 0.8009\n",
      "f1 = 0.4454\n",
      "*AUC is 0.8264\n",
      "\n",
      "After dropping NotAbleToAffordDoctor:\n",
      "accuracy = 71.7479%\n",
      "precision = 30.8449%\n",
      "recall = 0.7953\n",
      "f1 = 0.4445\n",
      "*AUC is 0.8234\n",
      "\n",
      "After dropping GeneralHealth:\n",
      "accuracy = 71.0718%\n",
      "precision = 29.9646%\n",
      "recall = 0.7742\n",
      "f1 = 0.4321\n",
      "*AUC is 0.8112\n",
      "\n",
      "After dropping MentalHealth:\n",
      "accuracy = 71.7715%\n",
      "precision = 30.8772%\n",
      "recall = 0.7961\n",
      "f1 = 0.4450\n",
      "*AUC is 0.8261\n",
      "\n",
      "After dropping PhysicalHealth:\n",
      "accuracy = 71.7380%\n",
      "precision = 30.8778%\n",
      "recall = 0.7981\n",
      "f1 = 0.4453\n",
      "*AUC is 0.8256\n",
      "\n",
      "After dropping HardToClimbStairs:\n",
      "accuracy = 71.6572%\n",
      "precision = 30.8203%\n",
      "recall = 0.7988\n",
      "f1 = 0.4448\n",
      "*AUC is 0.8240\n",
      "\n",
      "After dropping BiologicalSex:\n",
      "accuracy = 71.7006%\n",
      "precision = 30.8299%\n",
      "recall = 0.7970\n",
      "f1 = 0.4446\n",
      "*AUC is 0.8254\n",
      "\n",
      "After dropping AgeBracket:\n",
      "accuracy = 71.8031%\n",
      "precision = 30.5435%\n",
      "recall = 0.7723\n",
      "f1 = 0.4377\n",
      "*AUC is 0.8119\n",
      "\n",
      "After dropping EducationBracket:\n",
      "accuracy = 71.5409%\n",
      "precision = 30.6924%\n",
      "recall = 0.7967\n",
      "f1 = 0.4431\n",
      "*AUC is 0.8235\n",
      "\n",
      "After dropping IncomeBracket:\n",
      "accuracy = 71.5449%\n",
      "precision = 30.6460%\n",
      "recall = 0.7934\n",
      "f1 = 0.4421\n",
      "*AUC is 0.8231\n",
      "\n",
      "After dropping Zodiac:\n",
      "accuracy = 71.8326%\n",
      "precision = 30.9739%\n",
      "recall = 0.7992\n",
      "f1 = 0.4465\n",
      "*AUC is 0.8259\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model1 = adaboost_classification(scaled, y, 0, '')\n",
    "for i in range(len(predictors)):\n",
    "    temp = predictors[:]\n",
    "    temp.pop(i)\n",
    "    model2 = adaboost_classification(df[temp], y, 0,predictors[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Build a model using adaBoost. Doing so: What is the best predictor of diabetes and what is the AUC of this model?\n",
    "\n",
    "To improve the performance of the AdaBoostClassifier, I used GridSearchCV to find the optimal hyperparameters. I wrote an adaboost_classification function that split the data into training and testing sets and fitted the AdaBoostClassifier using balanced class_weight, algorithm=\"SAMME.R\", n_estimators=200, and learning_rate=0.1. After evaluating the model using evaluation metrics and AUC, I built 22 models, including one with all predictors and 21 with one predictor removed.\n",
    "\n",
    "By using balanced class_weight, the weights of different classes were adjusted, while learning_rate controlled the contribution of each estimator to the final prediction. Algorithm was used to update the weights of the misclassified samples in each iteration. Evaluation metrics and AUC were used to assess the performance of the model.\n",
    "\n",
    "The analysis showed that GeneralHealth was the most important predictor, as removing it led to the largest decrease in AUC among all the models. Specifically, the AUC decreased from 0.8231 to 0.8112, which was the lowest observed in the model. \n",
    "\n",
    "This suggests that GeneralHealth plays a critical role in predicting the target variable due to its strong correlation with the predictor variable."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Which of these 5 models is the best to predict diabetes in this dataset?\n",
    "\n",
    "After evaluating the AUC values of 5 models, it was observed that the AUC values for all models, except for the decision tree model, ranged from 0.82 to 0.83. The decision tree model had an AUC value of approximately 80. I guess the reason is I did not find the best parameter for decision tree model\n",
    "\n",
    "I selected AUC as the primary evaluation metric instead of accuracy based on my professor's example in class. The example demonstrated that in certain cases, such as identifying phone scams, it may be better to prioritize minimizing false negatives even if it means accepting a high rate of false positives. AUC is a robust metric that can accurately reflect the performance of different models in such situations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>Myocardial</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruit</th>\n",
       "      <th>Vegetables</th>\n",
       "      <th>HeavyDrinker</th>\n",
       "      <th>HasHealthcare</th>\n",
       "      <th>NotAbleToAffordDoctor</th>\n",
       "      <th>GeneralHealth</th>\n",
       "      <th>MentalHealth</th>\n",
       "      <th>PhysicalHealth</th>\n",
       "      <th>HardToClimbStairs</th>\n",
       "      <th>BiologicalSex</th>\n",
       "      <th>AgeBracket</th>\n",
       "      <th>EducationBracket</th>\n",
       "      <th>IncomeBracket</th>\n",
       "      <th>Zodiac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Diabetes</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.263129</td>\n",
       "      <td>0.200276</td>\n",
       "      <td>0.216843</td>\n",
       "      <td>0.060789</td>\n",
       "      <td>0.105816</td>\n",
       "      <td>0.177282</td>\n",
       "      <td>-0.118133</td>\n",
       "      <td>-0.040779</td>\n",
       "      <td>-0.056584</td>\n",
       "      <td>-0.057056</td>\n",
       "      <td>0.016255</td>\n",
       "      <td>0.031433</td>\n",
       "      <td>0.293569</td>\n",
       "      <td>0.069315</td>\n",
       "      <td>0.171337</td>\n",
       "      <td>0.218344</td>\n",
       "      <td>0.031430</td>\n",
       "      <td>0.177442</td>\n",
       "      <td>-0.124456</td>\n",
       "      <td>-0.163919</td>\n",
       "      <td>-0.000197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HighBP</th>\n",
       "      <td>0.263129</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.298199</td>\n",
       "      <td>0.213748</td>\n",
       "      <td>0.096991</td>\n",
       "      <td>0.129575</td>\n",
       "      <td>0.209361</td>\n",
       "      <td>-0.125267</td>\n",
       "      <td>-0.040555</td>\n",
       "      <td>-0.061266</td>\n",
       "      <td>-0.003972</td>\n",
       "      <td>0.038425</td>\n",
       "      <td>0.017358</td>\n",
       "      <td>0.300530</td>\n",
       "      <td>0.056456</td>\n",
       "      <td>0.161212</td>\n",
       "      <td>0.223618</td>\n",
       "      <td>0.052207</td>\n",
       "      <td>0.344452</td>\n",
       "      <td>-0.141358</td>\n",
       "      <td>-0.171235</td>\n",
       "      <td>-0.002629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HighChol</th>\n",
       "      <td>0.200276</td>\n",
       "      <td>0.298199</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.106722</td>\n",
       "      <td>0.091299</td>\n",
       "      <td>0.092620</td>\n",
       "      <td>0.180765</td>\n",
       "      <td>-0.078046</td>\n",
       "      <td>-0.040859</td>\n",
       "      <td>-0.039874</td>\n",
       "      <td>-0.011543</td>\n",
       "      <td>0.042230</td>\n",
       "      <td>0.013310</td>\n",
       "      <td>0.208426</td>\n",
       "      <td>0.062069</td>\n",
       "      <td>0.121751</td>\n",
       "      <td>0.144672</td>\n",
       "      <td>0.031205</td>\n",
       "      <td>0.272318</td>\n",
       "      <td>-0.070802</td>\n",
       "      <td>-0.085459</td>\n",
       "      <td>0.001052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>0.216843</td>\n",
       "      <td>0.213748</td>\n",
       "      <td>0.106722</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013804</td>\n",
       "      <td>0.020153</td>\n",
       "      <td>0.052904</td>\n",
       "      <td>-0.147294</td>\n",
       "      <td>-0.087518</td>\n",
       "      <td>-0.062275</td>\n",
       "      <td>-0.048736</td>\n",
       "      <td>-0.018471</td>\n",
       "      <td>0.058206</td>\n",
       "      <td>0.239185</td>\n",
       "      <td>0.085310</td>\n",
       "      <td>0.121141</td>\n",
       "      <td>0.197078</td>\n",
       "      <td>0.042950</td>\n",
       "      <td>-0.036618</td>\n",
       "      <td>-0.103932</td>\n",
       "      <td>-0.100069</td>\n",
       "      <td>-0.001932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smoker</th>\n",
       "      <td>0.060789</td>\n",
       "      <td>0.096991</td>\n",
       "      <td>0.091299</td>\n",
       "      <td>0.013804</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.061173</td>\n",
       "      <td>0.114441</td>\n",
       "      <td>-0.087401</td>\n",
       "      <td>-0.077666</td>\n",
       "      <td>-0.030678</td>\n",
       "      <td>0.101619</td>\n",
       "      <td>-0.023251</td>\n",
       "      <td>0.048946</td>\n",
       "      <td>0.163143</td>\n",
       "      <td>0.092196</td>\n",
       "      <td>0.116460</td>\n",
       "      <td>0.122463</td>\n",
       "      <td>0.093662</td>\n",
       "      <td>0.120641</td>\n",
       "      <td>-0.161955</td>\n",
       "      <td>-0.123937</td>\n",
       "      <td>0.000975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stroke</th>\n",
       "      <td>0.105816</td>\n",
       "      <td>0.129575</td>\n",
       "      <td>0.092620</td>\n",
       "      <td>0.020153</td>\n",
       "      <td>0.061173</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.203002</td>\n",
       "      <td>-0.069151</td>\n",
       "      <td>-0.013389</td>\n",
       "      <td>-0.041124</td>\n",
       "      <td>-0.016950</td>\n",
       "      <td>0.008776</td>\n",
       "      <td>0.034804</td>\n",
       "      <td>0.177942</td>\n",
       "      <td>0.070172</td>\n",
       "      <td>0.148944</td>\n",
       "      <td>0.176567</td>\n",
       "      <td>0.002978</td>\n",
       "      <td>0.126974</td>\n",
       "      <td>-0.076009</td>\n",
       "      <td>-0.128599</td>\n",
       "      <td>-0.001933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Myocardial</th>\n",
       "      <td>0.177282</td>\n",
       "      <td>0.209361</td>\n",
       "      <td>0.180765</td>\n",
       "      <td>0.052904</td>\n",
       "      <td>0.114441</td>\n",
       "      <td>0.203002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.087299</td>\n",
       "      <td>-0.019790</td>\n",
       "      <td>-0.039167</td>\n",
       "      <td>-0.028991</td>\n",
       "      <td>0.018734</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>0.258383</td>\n",
       "      <td>0.064621</td>\n",
       "      <td>0.181698</td>\n",
       "      <td>0.212709</td>\n",
       "      <td>0.086096</td>\n",
       "      <td>0.221618</td>\n",
       "      <td>-0.099600</td>\n",
       "      <td>-0.141011</td>\n",
       "      <td>-0.001232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhysActivity</th>\n",
       "      <td>-0.118133</td>\n",
       "      <td>-0.125267</td>\n",
       "      <td>-0.078046</td>\n",
       "      <td>-0.147294</td>\n",
       "      <td>-0.087401</td>\n",
       "      <td>-0.069151</td>\n",
       "      <td>-0.087299</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.142756</td>\n",
       "      <td>0.153150</td>\n",
       "      <td>0.012392</td>\n",
       "      <td>0.035505</td>\n",
       "      <td>-0.061638</td>\n",
       "      <td>-0.266186</td>\n",
       "      <td>-0.125587</td>\n",
       "      <td>-0.219230</td>\n",
       "      <td>-0.253174</td>\n",
       "      <td>0.032482</td>\n",
       "      <td>-0.092511</td>\n",
       "      <td>0.199658</td>\n",
       "      <td>0.198539</td>\n",
       "      <td>-0.000842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fruit</th>\n",
       "      <td>-0.040779</td>\n",
       "      <td>-0.040555</td>\n",
       "      <td>-0.040859</td>\n",
       "      <td>-0.087518</td>\n",
       "      <td>-0.077666</td>\n",
       "      <td>-0.013389</td>\n",
       "      <td>-0.019790</td>\n",
       "      <td>0.142756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.254342</td>\n",
       "      <td>-0.035288</td>\n",
       "      <td>0.031544</td>\n",
       "      <td>-0.044243</td>\n",
       "      <td>-0.103854</td>\n",
       "      <td>-0.068217</td>\n",
       "      <td>-0.044633</td>\n",
       "      <td>-0.048352</td>\n",
       "      <td>-0.091175</td>\n",
       "      <td>0.064547</td>\n",
       "      <td>0.110187</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>-0.002255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vegetables</th>\n",
       "      <td>-0.056584</td>\n",
       "      <td>-0.061266</td>\n",
       "      <td>-0.039874</td>\n",
       "      <td>-0.062275</td>\n",
       "      <td>-0.030678</td>\n",
       "      <td>-0.041124</td>\n",
       "      <td>-0.039167</td>\n",
       "      <td>0.153150</td>\n",
       "      <td>0.254342</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.021064</td>\n",
       "      <td>0.029584</td>\n",
       "      <td>-0.032232</td>\n",
       "      <td>-0.123066</td>\n",
       "      <td>-0.058884</td>\n",
       "      <td>-0.064290</td>\n",
       "      <td>-0.080506</td>\n",
       "      <td>-0.064765</td>\n",
       "      <td>-0.009771</td>\n",
       "      <td>0.154329</td>\n",
       "      <td>0.151087</td>\n",
       "      <td>-0.000732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HeavyDrinker</th>\n",
       "      <td>-0.057056</td>\n",
       "      <td>-0.003972</td>\n",
       "      <td>-0.011543</td>\n",
       "      <td>-0.048736</td>\n",
       "      <td>0.101619</td>\n",
       "      <td>-0.016950</td>\n",
       "      <td>-0.028991</td>\n",
       "      <td>0.012392</td>\n",
       "      <td>-0.035288</td>\n",
       "      <td>0.021064</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.010488</td>\n",
       "      <td>0.004684</td>\n",
       "      <td>-0.036724</td>\n",
       "      <td>0.024716</td>\n",
       "      <td>-0.026415</td>\n",
       "      <td>-0.037668</td>\n",
       "      <td>0.005740</td>\n",
       "      <td>-0.034578</td>\n",
       "      <td>0.023997</td>\n",
       "      <td>0.053619</td>\n",
       "      <td>-0.001216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HasHealthcare</th>\n",
       "      <td>0.016255</td>\n",
       "      <td>0.038425</td>\n",
       "      <td>0.042230</td>\n",
       "      <td>-0.018471</td>\n",
       "      <td>-0.023251</td>\n",
       "      <td>0.008776</td>\n",
       "      <td>0.018734</td>\n",
       "      <td>0.035505</td>\n",
       "      <td>0.031544</td>\n",
       "      <td>0.029584</td>\n",
       "      <td>-0.010488</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.232532</td>\n",
       "      <td>-0.040817</td>\n",
       "      <td>-0.052707</td>\n",
       "      <td>-0.008276</td>\n",
       "      <td>0.007074</td>\n",
       "      <td>-0.019405</td>\n",
       "      <td>0.138046</td>\n",
       "      <td>0.122514</td>\n",
       "      <td>0.157999</td>\n",
       "      <td>0.000502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NotAbleToAffordDoctor</th>\n",
       "      <td>0.031433</td>\n",
       "      <td>0.017358</td>\n",
       "      <td>0.013310</td>\n",
       "      <td>0.058206</td>\n",
       "      <td>0.048946</td>\n",
       "      <td>0.034804</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>-0.061638</td>\n",
       "      <td>-0.044243</td>\n",
       "      <td>-0.032232</td>\n",
       "      <td>0.004684</td>\n",
       "      <td>-0.232532</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166397</td>\n",
       "      <td>0.192107</td>\n",
       "      <td>0.148998</td>\n",
       "      <td>0.118447</td>\n",
       "      <td>-0.044931</td>\n",
       "      <td>-0.119777</td>\n",
       "      <td>-0.100701</td>\n",
       "      <td>-0.203182</td>\n",
       "      <td>0.001856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GeneralHealth</th>\n",
       "      <td>0.293569</td>\n",
       "      <td>0.300530</td>\n",
       "      <td>0.208426</td>\n",
       "      <td>0.239185</td>\n",
       "      <td>0.163143</td>\n",
       "      <td>0.177942</td>\n",
       "      <td>0.258383</td>\n",
       "      <td>-0.266186</td>\n",
       "      <td>-0.103854</td>\n",
       "      <td>-0.123066</td>\n",
       "      <td>-0.036724</td>\n",
       "      <td>-0.040817</td>\n",
       "      <td>0.166397</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.301674</td>\n",
       "      <td>0.524364</td>\n",
       "      <td>0.456920</td>\n",
       "      <td>-0.006091</td>\n",
       "      <td>0.152450</td>\n",
       "      <td>-0.284912</td>\n",
       "      <td>-0.370014</td>\n",
       "      <td>0.001435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MentalHealth</th>\n",
       "      <td>0.069315</td>\n",
       "      <td>0.056456</td>\n",
       "      <td>0.062069</td>\n",
       "      <td>0.085310</td>\n",
       "      <td>0.092196</td>\n",
       "      <td>0.070172</td>\n",
       "      <td>0.064621</td>\n",
       "      <td>-0.125587</td>\n",
       "      <td>-0.068217</td>\n",
       "      <td>-0.058884</td>\n",
       "      <td>0.024716</td>\n",
       "      <td>-0.052707</td>\n",
       "      <td>0.192107</td>\n",
       "      <td>0.301674</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.353619</td>\n",
       "      <td>0.233688</td>\n",
       "      <td>-0.080705</td>\n",
       "      <td>-0.092068</td>\n",
       "      <td>-0.101830</td>\n",
       "      <td>-0.209806</td>\n",
       "      <td>0.002008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhysicalHealth</th>\n",
       "      <td>0.171337</td>\n",
       "      <td>0.161212</td>\n",
       "      <td>0.121751</td>\n",
       "      <td>0.121141</td>\n",
       "      <td>0.116460</td>\n",
       "      <td>0.148944</td>\n",
       "      <td>0.181698</td>\n",
       "      <td>-0.219230</td>\n",
       "      <td>-0.044633</td>\n",
       "      <td>-0.064290</td>\n",
       "      <td>-0.026415</td>\n",
       "      <td>-0.008276</td>\n",
       "      <td>0.148998</td>\n",
       "      <td>0.524364</td>\n",
       "      <td>0.353619</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.478417</td>\n",
       "      <td>-0.043137</td>\n",
       "      <td>0.099130</td>\n",
       "      <td>-0.155093</td>\n",
       "      <td>-0.266799</td>\n",
       "      <td>0.001977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HardToClimbStairs</th>\n",
       "      <td>0.218344</td>\n",
       "      <td>0.223618</td>\n",
       "      <td>0.144672</td>\n",
       "      <td>0.197078</td>\n",
       "      <td>0.122463</td>\n",
       "      <td>0.176567</td>\n",
       "      <td>0.212709</td>\n",
       "      <td>-0.253174</td>\n",
       "      <td>-0.048352</td>\n",
       "      <td>-0.080506</td>\n",
       "      <td>-0.037668</td>\n",
       "      <td>0.007074</td>\n",
       "      <td>0.118447</td>\n",
       "      <td>0.456920</td>\n",
       "      <td>0.233688</td>\n",
       "      <td>0.478417</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.070299</td>\n",
       "      <td>0.204450</td>\n",
       "      <td>-0.192642</td>\n",
       "      <td>-0.320124</td>\n",
       "      <td>0.003291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BiologicalSex</th>\n",
       "      <td>0.031430</td>\n",
       "      <td>0.052207</td>\n",
       "      <td>0.031205</td>\n",
       "      <td>0.042950</td>\n",
       "      <td>0.093662</td>\n",
       "      <td>0.002978</td>\n",
       "      <td>0.086096</td>\n",
       "      <td>0.032482</td>\n",
       "      <td>-0.091175</td>\n",
       "      <td>-0.064765</td>\n",
       "      <td>0.005740</td>\n",
       "      <td>-0.019405</td>\n",
       "      <td>-0.044931</td>\n",
       "      <td>-0.006091</td>\n",
       "      <td>-0.080705</td>\n",
       "      <td>-0.043137</td>\n",
       "      <td>-0.070299</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.027340</td>\n",
       "      <td>0.019480</td>\n",
       "      <td>0.127141</td>\n",
       "      <td>0.001671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgeBracket</th>\n",
       "      <td>0.177442</td>\n",
       "      <td>0.344452</td>\n",
       "      <td>0.272318</td>\n",
       "      <td>-0.036618</td>\n",
       "      <td>0.120641</td>\n",
       "      <td>0.126974</td>\n",
       "      <td>0.221618</td>\n",
       "      <td>-0.092511</td>\n",
       "      <td>0.064547</td>\n",
       "      <td>-0.009771</td>\n",
       "      <td>-0.034578</td>\n",
       "      <td>0.138046</td>\n",
       "      <td>-0.119777</td>\n",
       "      <td>0.152450</td>\n",
       "      <td>-0.092068</td>\n",
       "      <td>0.099130</td>\n",
       "      <td>0.204450</td>\n",
       "      <td>-0.027340</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.101901</td>\n",
       "      <td>-0.127775</td>\n",
       "      <td>-0.002632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EducationBracket</th>\n",
       "      <td>-0.124456</td>\n",
       "      <td>-0.141358</td>\n",
       "      <td>-0.070802</td>\n",
       "      <td>-0.103932</td>\n",
       "      <td>-0.161955</td>\n",
       "      <td>-0.076009</td>\n",
       "      <td>-0.099600</td>\n",
       "      <td>0.199658</td>\n",
       "      <td>0.110187</td>\n",
       "      <td>0.154329</td>\n",
       "      <td>0.023997</td>\n",
       "      <td>0.122514</td>\n",
       "      <td>-0.100701</td>\n",
       "      <td>-0.284912</td>\n",
       "      <td>-0.101830</td>\n",
       "      <td>-0.155093</td>\n",
       "      <td>-0.192642</td>\n",
       "      <td>0.019480</td>\n",
       "      <td>-0.101901</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.449106</td>\n",
       "      <td>-0.001313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IncomeBracket</th>\n",
       "      <td>-0.163919</td>\n",
       "      <td>-0.171235</td>\n",
       "      <td>-0.085459</td>\n",
       "      <td>-0.100069</td>\n",
       "      <td>-0.123937</td>\n",
       "      <td>-0.128599</td>\n",
       "      <td>-0.141011</td>\n",
       "      <td>0.198539</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>0.151087</td>\n",
       "      <td>0.053619</td>\n",
       "      <td>0.157999</td>\n",
       "      <td>-0.203182</td>\n",
       "      <td>-0.370014</td>\n",
       "      <td>-0.209806</td>\n",
       "      <td>-0.266799</td>\n",
       "      <td>-0.320124</td>\n",
       "      <td>0.127141</td>\n",
       "      <td>-0.127775</td>\n",
       "      <td>0.449106</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zodiac</th>\n",
       "      <td>-0.000197</td>\n",
       "      <td>-0.002629</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>-0.001932</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>-0.001933</td>\n",
       "      <td>-0.001232</td>\n",
       "      <td>-0.000842</td>\n",
       "      <td>-0.002255</td>\n",
       "      <td>-0.000732</td>\n",
       "      <td>-0.001216</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.001856</td>\n",
       "      <td>0.001435</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>0.001977</td>\n",
       "      <td>0.003291</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>-0.002632</td>\n",
       "      <td>-0.001313</td>\n",
       "      <td>-0.003201</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Diabetes    HighBP  HighChol       BMI    Smoker  \\\n",
       "Diabetes               1.000000  0.263129  0.200276  0.216843  0.060789   \n",
       "HighBP                 0.263129  1.000000  0.298199  0.213748  0.096991   \n",
       "HighChol               0.200276  0.298199  1.000000  0.106722  0.091299   \n",
       "BMI                    0.216843  0.213748  0.106722  1.000000  0.013804   \n",
       "Smoker                 0.060789  0.096991  0.091299  0.013804  1.000000   \n",
       "Stroke                 0.105816  0.129575  0.092620  0.020153  0.061173   \n",
       "Myocardial             0.177282  0.209361  0.180765  0.052904  0.114441   \n",
       "PhysActivity          -0.118133 -0.125267 -0.078046 -0.147294 -0.087401   \n",
       "Fruit                 -0.040779 -0.040555 -0.040859 -0.087518 -0.077666   \n",
       "Vegetables            -0.056584 -0.061266 -0.039874 -0.062275 -0.030678   \n",
       "HeavyDrinker          -0.057056 -0.003972 -0.011543 -0.048736  0.101619   \n",
       "HasHealthcare          0.016255  0.038425  0.042230 -0.018471 -0.023251   \n",
       "NotAbleToAffordDoctor  0.031433  0.017358  0.013310  0.058206  0.048946   \n",
       "GeneralHealth          0.293569  0.300530  0.208426  0.239185  0.163143   \n",
       "MentalHealth           0.069315  0.056456  0.062069  0.085310  0.092196   \n",
       "PhysicalHealth         0.171337  0.161212  0.121751  0.121141  0.116460   \n",
       "HardToClimbStairs      0.218344  0.223618  0.144672  0.197078  0.122463   \n",
       "BiologicalSex          0.031430  0.052207  0.031205  0.042950  0.093662   \n",
       "AgeBracket             0.177442  0.344452  0.272318 -0.036618  0.120641   \n",
       "EducationBracket      -0.124456 -0.141358 -0.070802 -0.103932 -0.161955   \n",
       "IncomeBracket         -0.163919 -0.171235 -0.085459 -0.100069 -0.123937   \n",
       "Zodiac                -0.000197 -0.002629  0.001052 -0.001932  0.000975   \n",
       "\n",
       "                         Stroke  Myocardial  PhysActivity     Fruit  \\\n",
       "Diabetes               0.105816    0.177282     -0.118133 -0.040779   \n",
       "HighBP                 0.129575    0.209361     -0.125267 -0.040555   \n",
       "HighChol               0.092620    0.180765     -0.078046 -0.040859   \n",
       "BMI                    0.020153    0.052904     -0.147294 -0.087518   \n",
       "Smoker                 0.061173    0.114441     -0.087401 -0.077666   \n",
       "Stroke                 1.000000    0.203002     -0.069151 -0.013389   \n",
       "Myocardial             0.203002    1.000000     -0.087299 -0.019790   \n",
       "PhysActivity          -0.069151   -0.087299      1.000000  0.142756   \n",
       "Fruit                 -0.013389   -0.019790      0.142756  1.000000   \n",
       "Vegetables            -0.041124   -0.039167      0.153150  0.254342   \n",
       "HeavyDrinker          -0.016950   -0.028991      0.012392 -0.035288   \n",
       "HasHealthcare          0.008776    0.018734      0.035505  0.031544   \n",
       "NotAbleToAffordDoctor  0.034804    0.031000     -0.061638 -0.044243   \n",
       "GeneralHealth          0.177942    0.258383     -0.266186 -0.103854   \n",
       "MentalHealth           0.070172    0.064621     -0.125587 -0.068217   \n",
       "PhysicalHealth         0.148944    0.181698     -0.219230 -0.044633   \n",
       "HardToClimbStairs      0.176567    0.212709     -0.253174 -0.048352   \n",
       "BiologicalSex          0.002978    0.086096      0.032482 -0.091175   \n",
       "AgeBracket             0.126974    0.221618     -0.092511  0.064547   \n",
       "EducationBracket      -0.076009   -0.099600      0.199658  0.110187   \n",
       "IncomeBracket         -0.128599   -0.141011      0.198539  0.079929   \n",
       "Zodiac                -0.001933   -0.001232     -0.000842 -0.002255   \n",
       "\n",
       "                       Vegetables  HeavyDrinker  HasHealthcare  \\\n",
       "Diabetes                -0.056584     -0.057056       0.016255   \n",
       "HighBP                  -0.061266     -0.003972       0.038425   \n",
       "HighChol                -0.039874     -0.011543       0.042230   \n",
       "BMI                     -0.062275     -0.048736      -0.018471   \n",
       "Smoker                  -0.030678      0.101619      -0.023251   \n",
       "Stroke                  -0.041124     -0.016950       0.008776   \n",
       "Myocardial              -0.039167     -0.028991       0.018734   \n",
       "PhysActivity             0.153150      0.012392       0.035505   \n",
       "Fruit                    0.254342     -0.035288       0.031544   \n",
       "Vegetables               1.000000      0.021064       0.029584   \n",
       "HeavyDrinker             0.021064      1.000000      -0.010488   \n",
       "HasHealthcare            0.029584     -0.010488       1.000000   \n",
       "NotAbleToAffordDoctor   -0.032232      0.004684      -0.232532   \n",
       "GeneralHealth           -0.123066     -0.036724      -0.040817   \n",
       "MentalHealth            -0.058884      0.024716      -0.052707   \n",
       "PhysicalHealth          -0.064290     -0.026415      -0.008276   \n",
       "HardToClimbStairs       -0.080506     -0.037668       0.007074   \n",
       "BiologicalSex           -0.064765      0.005740      -0.019405   \n",
       "AgeBracket              -0.009771     -0.034578       0.138046   \n",
       "EducationBracket         0.154329      0.023997       0.122514   \n",
       "IncomeBracket            0.151087      0.053619       0.157999   \n",
       "Zodiac                  -0.000732     -0.001216       0.000502   \n",
       "\n",
       "                       NotAbleToAffordDoctor  GeneralHealth  MentalHealth  \\\n",
       "Diabetes                            0.031433       0.293569      0.069315   \n",
       "HighBP                              0.017358       0.300530      0.056456   \n",
       "HighChol                            0.013310       0.208426      0.062069   \n",
       "BMI                                 0.058206       0.239185      0.085310   \n",
       "Smoker                              0.048946       0.163143      0.092196   \n",
       "Stroke                              0.034804       0.177942      0.070172   \n",
       "Myocardial                          0.031000       0.258383      0.064621   \n",
       "PhysActivity                       -0.061638      -0.266186     -0.125587   \n",
       "Fruit                              -0.044243      -0.103854     -0.068217   \n",
       "Vegetables                         -0.032232      -0.123066     -0.058884   \n",
       "HeavyDrinker                        0.004684      -0.036724      0.024716   \n",
       "HasHealthcare                      -0.232532      -0.040817     -0.052707   \n",
       "NotAbleToAffordDoctor               1.000000       0.166397      0.192107   \n",
       "GeneralHealth                       0.166397       1.000000      0.301674   \n",
       "MentalHealth                        0.192107       0.301674      1.000000   \n",
       "PhysicalHealth                      0.148998       0.524364      0.353619   \n",
       "HardToClimbStairs                   0.118447       0.456920      0.233688   \n",
       "BiologicalSex                      -0.044931      -0.006091     -0.080705   \n",
       "AgeBracket                         -0.119777       0.152450     -0.092068   \n",
       "EducationBracket                   -0.100701      -0.284912     -0.101830   \n",
       "IncomeBracket                      -0.203182      -0.370014     -0.209806   \n",
       "Zodiac                              0.001856       0.001435      0.002008   \n",
       "\n",
       "                       PhysicalHealth  HardToClimbStairs  BiologicalSex  \\\n",
       "Diabetes                     0.171337           0.218344       0.031430   \n",
       "HighBP                       0.161212           0.223618       0.052207   \n",
       "HighChol                     0.121751           0.144672       0.031205   \n",
       "BMI                          0.121141           0.197078       0.042950   \n",
       "Smoker                       0.116460           0.122463       0.093662   \n",
       "Stroke                       0.148944           0.176567       0.002978   \n",
       "Myocardial                   0.181698           0.212709       0.086096   \n",
       "PhysActivity                -0.219230          -0.253174       0.032482   \n",
       "Fruit                       -0.044633          -0.048352      -0.091175   \n",
       "Vegetables                  -0.064290          -0.080506      -0.064765   \n",
       "HeavyDrinker                -0.026415          -0.037668       0.005740   \n",
       "HasHealthcare               -0.008276           0.007074      -0.019405   \n",
       "NotAbleToAffordDoctor        0.148998           0.118447      -0.044931   \n",
       "GeneralHealth                0.524364           0.456920      -0.006091   \n",
       "MentalHealth                 0.353619           0.233688      -0.080705   \n",
       "PhysicalHealth               1.000000           0.478417      -0.043137   \n",
       "HardToClimbStairs            0.478417           1.000000      -0.070299   \n",
       "BiologicalSex               -0.043137          -0.070299       1.000000   \n",
       "AgeBracket                   0.099130           0.204450      -0.027340   \n",
       "EducationBracket            -0.155093          -0.192642       0.019480   \n",
       "IncomeBracket               -0.266799          -0.320124       0.127141   \n",
       "Zodiac                       0.001977           0.003291       0.001671   \n",
       "\n",
       "                       AgeBracket  EducationBracket  IncomeBracket    Zodiac  \n",
       "Diabetes                 0.177442         -0.124456      -0.163919 -0.000197  \n",
       "HighBP                   0.344452         -0.141358      -0.171235 -0.002629  \n",
       "HighChol                 0.272318         -0.070802      -0.085459  0.001052  \n",
       "BMI                     -0.036618         -0.103932      -0.100069 -0.001932  \n",
       "Smoker                   0.120641         -0.161955      -0.123937  0.000975  \n",
       "Stroke                   0.126974         -0.076009      -0.128599 -0.001933  \n",
       "Myocardial               0.221618         -0.099600      -0.141011 -0.001232  \n",
       "PhysActivity            -0.092511          0.199658       0.198539 -0.000842  \n",
       "Fruit                    0.064547          0.110187       0.079929 -0.002255  \n",
       "Vegetables              -0.009771          0.154329       0.151087 -0.000732  \n",
       "HeavyDrinker            -0.034578          0.023997       0.053619 -0.001216  \n",
       "HasHealthcare            0.138046          0.122514       0.157999  0.000502  \n",
       "NotAbleToAffordDoctor   -0.119777         -0.100701      -0.203182  0.001856  \n",
       "GeneralHealth            0.152450         -0.284912      -0.370014  0.001435  \n",
       "MentalHealth            -0.092068         -0.101830      -0.209806  0.002008  \n",
       "PhysicalHealth           0.099130         -0.155093      -0.266799  0.001977  \n",
       "HardToClimbStairs        0.204450         -0.192642      -0.320124  0.003291  \n",
       "BiologicalSex           -0.027340          0.019480       0.127141  0.001671  \n",
       "AgeBracket               1.000000         -0.101901      -0.127775 -0.002632  \n",
       "EducationBracket        -0.101901          1.000000       0.449106 -0.001313  \n",
       "IncomeBracket           -0.127775          0.449106       1.000000 -0.003201  \n",
       "Zodiac                  -0.002632         -0.001313      -0.003201  1.000000  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeneralHealth      PhysicalHealth       0.524364\n",
      "                   HardToClimbStairs    0.456920\n",
      "PhysicalHealth     GeneralHealth        0.524364\n",
      "                   HardToClimbStairs    0.478417\n",
      "HardToClimbStairs  GeneralHealth        0.456920\n",
      "                   PhysicalHealth       0.478417\n",
      "EducationBracket   IncomeBracket        0.449106\n",
      "IncomeBracket      EducationBracket     0.449106\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "corr_matrix = df.corr()\n",
    "mask = (abs(corr_matrix) >= 0.4) & (corr_matrix != 1)\n",
    "\n",
    "filtered_corr = corr_matrix.where(mask).stack()\n",
    "\n",
    "print(filtered_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BMI</th>\n",
       "      <th>GeneralHealth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253675</th>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253676</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253677</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253678</th>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253679</th>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253680 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        BMI  GeneralHealth\n",
       "0        40              5\n",
       "1        25              3\n",
       "2        28              5\n",
       "3        27              2\n",
       "4        24              2\n",
       "...     ...            ...\n",
       "253675   45              3\n",
       "253676   18              4\n",
       "253677   28              1\n",
       "253678   23              3\n",
       "253679   25              2\n",
       "\n",
       "[253680 rows x 2 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['BMI', 'GeneralHealth']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>Myocardial</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruit</th>\n",
       "      <th>Vegetables</th>\n",
       "      <th>HeavyDrinker</th>\n",
       "      <th>HasHealthcare</th>\n",
       "      <th>NotAbleToAffordDoctor</th>\n",
       "      <th>GeneralHealth</th>\n",
       "      <th>MentalHealth</th>\n",
       "      <th>PhysicalHealth</th>\n",
       "      <th>HardToClimbStairs</th>\n",
       "      <th>BiologicalSex</th>\n",
       "      <th>AgeBracket</th>\n",
       "      <th>EducationBracket</th>\n",
       "      <th>IncomeBracket</th>\n",
       "      <th>Zodiac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes  HighBP  HighChol  BMI  Smoker  Stroke  Myocardial  PhysActivity  \\\n",
       "0         0       1         1   40       1       0           0             0   \n",
       "1         0       0         0   25       1       0           0             1   \n",
       "2         0       1         1   28       0       0           0             0   \n",
       "3         0       1         0   27       0       0           0             1   \n",
       "4         0       1         1   24       0       0           0             1   \n",
       "\n",
       "   Fruit  Vegetables  HeavyDrinker  HasHealthcare  NotAbleToAffordDoctor  \\\n",
       "0      0           1             0              1                      0   \n",
       "1      0           0             0              0                      1   \n",
       "2      1           0             0              1                      1   \n",
       "3      1           1             0              1                      0   \n",
       "4      1           1             0              1                      0   \n",
       "\n",
       "   GeneralHealth  MentalHealth  PhysicalHealth  HardToClimbStairs  \\\n",
       "0              5            18              15                  1   \n",
       "1              3             0               0                  0   \n",
       "2              5            30              30                  1   \n",
       "3              2             0               0                  0   \n",
       "4              2             3               0                  0   \n",
       "\n",
       "   BiologicalSex  AgeBracket  EducationBracket  IncomeBracket  Zodiac  \n",
       "0              1           9                 4              3      10  \n",
       "1              1           7                 6              1      11  \n",
       "2              1           9                 4              8       2  \n",
       "3              1          11                 3              6      11  \n",
       "4              1          11                 5              4       8  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['IncomeBracket', 'HardToClimbStairs', 'GeneralHealth', 'PhysicalHealth']\n",
    "df1 = df.drop(columns=columns_to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = list(df1.columns)\n",
    "predictors.remove('Diabetes')\n",
    "X = df1[predictors]\n",
    "y = df1['Diabetes']\n",
    "scaled = StandardScaler().fit_transform(X)\n",
    "scaled = pd.DataFrame(scaled, columns=X.columns)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 71.2610%\n",
      "precision = 29.8016%\n",
      "recall = 0.7540\n",
      "f1 = 0.4272\n",
      "*AUC is  0.8044369414237343\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping  HighBP\n",
      "accuracy = 70.5061%\n",
      "precision = 28.8481%\n",
      "recall = 0.7332\n",
      "f1 = 0.4140\n",
      "*AUC is  0.7904152894880827\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping  HighChol\n",
      "accuracy = 70.6619%\n",
      "precision = 29.2639%\n",
      "recall = 0.7509\n",
      "f1 = 0.4212\n",
      "*AUC is  0.7963659180789195\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping  BMI\n",
      "accuracy = 69.6626%\n",
      "precision = 28.2362%\n",
      "recall = 0.7360\n",
      "f1 = 0.4081\n",
      "*AUC is  0.7789721013854082\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping  Smoker\n",
      "accuracy = 70.9871%\n",
      "precision = 29.6029%\n",
      "recall = 0.7557\n",
      "f1 = 0.4254\n",
      "*AUC is  0.8036182292497637\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping  Stroke\n",
      "accuracy = 70.8629%\n",
      "precision = 29.4596%\n",
      "recall = 0.7530\n",
      "f1 = 0.4235\n",
      "*AUC is  0.8018382551196791\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping  Myocardial\n",
      "accuracy = 70.6284%\n",
      "precision = 29.2684%\n",
      "recall = 0.7529\n",
      "f1 = 0.4215\n",
      "*AUC is  0.80134840263746\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping  PhysActivity\n",
      "accuracy = 71.0028%\n",
      "precision = 29.6268%\n",
      "recall = 0.7563\n",
      "f1 = 0.4258\n",
      "*AUC is  0.803236023909161\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping  Fruit\n",
      "accuracy = 70.9634%\n",
      "precision = 29.5503%\n",
      "recall = 0.7536\n",
      "f1 = 0.4245\n",
      "*AUC is  0.8024551504096071\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping  Vegetables\n",
      "accuracy = 71.1684%\n",
      "precision = 29.6850%\n",
      "recall = 0.7515\n",
      "f1 = 0.4256\n",
      "*AUC is  0.803400468889232\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping  HeavyDrinker\n",
      "accuracy = 70.6954%\n",
      "precision = 29.3645%\n",
      "recall = 0.7555\n",
      "f1 = 0.4229\n",
      "*AUC is  0.8016342987383418\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping  HasHealthcare\n",
      "accuracy = 71.1014%\n",
      "precision = 29.6654%\n",
      "recall = 0.7537\n",
      "f1 = 0.4257\n",
      "*AUC is  0.8034127801588469\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping  NotAbleToAffordDoctor\n",
      "accuracy = 70.9003%\n",
      "precision = 29.4789%\n",
      "recall = 0.7523\n",
      "f1 = 0.4236\n",
      "*AUC is  0.8030498111770175\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping  MentalHealth\n",
      "accuracy = 71.1250%\n",
      "precision = 29.6671%\n",
      "recall = 0.7526\n",
      "f1 = 0.4256\n",
      "*AUC is  0.8034930598961268\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping  BiologicalSex\n",
      "accuracy = 71.2315%\n",
      "precision = 29.7327%\n",
      "recall = 0.7512\n",
      "f1 = 0.4260\n",
      "*AUC is  0.8038985400360401\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping  AgeBracket\n",
      "accuracy = 71.0265%\n",
      "precision = 29.2491%\n",
      "recall = 0.7319\n",
      "f1 = 0.4180\n",
      "*AUC is  0.7935520537859743\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping  EducationBracket\n",
      "accuracy = 70.6402%\n",
      "precision = 29.3158%\n",
      "recall = 0.7552\n",
      "f1 = 0.4224\n",
      "*AUC is  0.7997941207793218\n",
      "\n",
      "After dropping  Zodiac\n",
      "accuracy = 70.6500%\n",
      "precision = 29.3903%\n",
      "recall = 0.7594\n",
      "f1 = 0.4238\n",
      "*AUC is  0.8026065274102978\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanggezheng/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model1 = logistic_regersion(scaled, y, 0, '')\n",
    "for i in range(len(predictors)):\n",
    "    temp = predictors[:]\n",
    "    temp.pop(i)\n",
    "    model2 = logistic_regersion(df1[temp], y, 0,predictors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 70.7742%\n",
      "precision = 29.4723%\n",
      "recall = 0.7583\n",
      "f1 = 0.4245\n",
      "*AUC is 0.8038\n",
      "\n",
      "After dropping HighBP:\n",
      "accuracy = 70.3958%\n",
      "precision = 28.8340%\n",
      "recall = 0.7376\n",
      "f1 = 0.4146\n",
      "*AUC is 0.7910\n",
      "\n",
      "After dropping HighChol:\n",
      "accuracy = 69.9996%\n",
      "precision = 28.8632%\n",
      "recall = 0.7584\n",
      "f1 = 0.4181\n",
      "*AUC is 0.7958\n",
      "\n",
      "After dropping BMI:\n",
      "accuracy = 69.2152%\n",
      "precision = 27.9872%\n",
      "recall = 0.7412\n",
      "f1 = 0.4063\n",
      "*AUC is 0.7786\n",
      "\n",
      "After dropping Smoker:\n",
      "accuracy = 70.7624%\n",
      "precision = 29.4406%\n",
      "recall = 0.7569\n",
      "f1 = 0.4239\n",
      "*AUC is 0.8037\n",
      "\n",
      "After dropping Stroke:\n",
      "accuracy = 70.6579%\n",
      "precision = 29.3567%\n",
      "recall = 0.7569\n",
      "f1 = 0.4231\n",
      "*AUC is 0.8028\n",
      "\n",
      "After dropping Myocardial:\n",
      "accuracy = 70.0942%\n",
      "precision = 28.9454%\n",
      "recall = 0.7590\n",
      "f1 = 0.4191\n",
      "*AUC is 0.8008\n",
      "\n",
      "After dropping PhysActivity:\n",
      "accuracy = 70.7072%\n",
      "precision = 29.4051%\n",
      "recall = 0.7575\n",
      "f1 = 0.4236\n",
      "*AUC is 0.8031\n",
      "\n",
      "After dropping Fruit:\n",
      "accuracy = 70.7998%\n",
      "precision = 29.4819%\n",
      "recall = 0.7576\n",
      "f1 = 0.4245\n",
      "*AUC is 0.8038\n",
      "\n",
      "After dropping Vegetables:\n",
      "accuracy = 70.7111%\n",
      "precision = 29.4238%\n",
      "recall = 0.7584\n",
      "f1 = 0.4240\n",
      "*AUC is 0.8036\n",
      "\n",
      "After dropping HeavyDrinker:\n",
      "accuracy = 70.5751%\n",
      "precision = 29.2883%\n",
      "recall = 0.7568\n",
      "f1 = 0.4223\n",
      "*AUC is 0.8019\n",
      "\n",
      "After dropping HasHealthcare:\n",
      "accuracy = 70.7860%\n",
      "precision = 29.4929%\n",
      "recall = 0.7590\n",
      "f1 = 0.4248\n",
      "*AUC is 0.8037\n",
      "\n",
      "After dropping NotAbleToAffordDoctor:\n",
      "accuracy = 70.7210%\n",
      "precision = 29.4073%\n",
      "recall = 0.7569\n",
      "f1 = 0.4236\n",
      "*AUC is 0.8036\n",
      "\n",
      "After dropping MentalHealth:\n",
      "accuracy = 70.6796%\n",
      "precision = 29.3830%\n",
      "recall = 0.7575\n",
      "f1 = 0.4234\n",
      "*AUC is 0.8030\n",
      "\n",
      "After dropping BiologicalSex:\n",
      "accuracy = 70.7919%\n",
      "precision = 29.4667%\n",
      "recall = 0.7570\n",
      "f1 = 0.4242\n",
      "*AUC is 0.8033\n",
      "\n",
      "After dropping AgeBracket:\n",
      "accuracy = 70.7880%\n",
      "precision = 29.0865%\n",
      "recall = 0.7339\n",
      "f1 = 0.4166\n",
      "*AUC is 0.7930\n",
      "\n",
      "After dropping EducationBracket:\n",
      "accuracy = 70.5653%\n",
      "precision = 29.3138%\n",
      "recall = 0.7588\n",
      "f1 = 0.4229\n",
      "*AUC is 0.8014\n",
      "\n",
      "After dropping Zodiac:\n",
      "accuracy = 70.7998%\n",
      "precision = 29.4952%\n",
      "recall = 0.7584\n",
      "f1 = 0.4247\n",
      "*AUC is 0.8038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model1 = svm_classification(scaled, y, 0, '')\n",
    "for i in range(len(predictors)):\n",
    "    temp = predictors[:]\n",
    "    temp.pop(i)\n",
    "    model2 = svm_classification(df1[temp], y, 0,predictors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 65.6457%\n",
      "precision = 26.5802%\n",
      "recall = 0.8042\n",
      "f1 = 0.3995\n",
      "*AUC is 0.7820\n",
      "\n",
      "After dropping HighBP:\n",
      "accuracy = 68.5963%\n",
      "precision = 27.1316%\n",
      "recall = 0.7175\n",
      "f1 = 0.3937\n",
      "*AUC is 0.7705\n",
      "\n",
      "After dropping HighChol:\n",
      "accuracy = 62.1570%\n",
      "precision = 25.0634%\n",
      "recall = 0.8355\n",
      "f1 = 0.3856\n",
      "*AUC is 0.7772\n",
      "\n",
      "After dropping BMI:\n",
      "accuracy = 67.5753%\n",
      "precision = 27.0172%\n",
      "recall = 0.7532\n",
      "f1 = 0.3977\n",
      "*AUC is 0.7689\n",
      "\n",
      "After dropping Smoker:\n",
      "accuracy = 65.6457%\n",
      "precision = 26.5802%\n",
      "recall = 0.8042\n",
      "f1 = 0.3995\n",
      "*AUC is 0.7820\n",
      "\n",
      "After dropping Stroke:\n",
      "accuracy = 65.6457%\n",
      "precision = 26.5802%\n",
      "recall = 0.8042\n",
      "f1 = 0.3995\n",
      "*AUC is 0.7820\n",
      "\n",
      "After dropping Myocardial:\n",
      "accuracy = 66.6470%\n",
      "precision = 26.9148%\n",
      "recall = 0.7851\n",
      "f1 = 0.4009\n",
      "*AUC is 0.7815\n",
      "\n",
      "After dropping PhysActivity:\n",
      "accuracy = 65.6457%\n",
      "precision = 26.5802%\n",
      "recall = 0.8042\n",
      "f1 = 0.3995\n",
      "*AUC is 0.7820\n",
      "\n",
      "After dropping Fruit:\n",
      "accuracy = 65.6457%\n",
      "precision = 26.5802%\n",
      "recall = 0.8042\n",
      "f1 = 0.3995\n",
      "*AUC is 0.7820\n",
      "\n",
      "After dropping Vegetables:\n",
      "accuracy = 65.6457%\n",
      "precision = 26.5802%\n",
      "recall = 0.8042\n",
      "f1 = 0.3995\n",
      "*AUC is 0.7820\n",
      "\n",
      "After dropping HeavyDrinker:\n",
      "accuracy = 65.6457%\n",
      "precision = 26.5802%\n",
      "recall = 0.8042\n",
      "f1 = 0.3995\n",
      "*AUC is 0.7820\n",
      "\n",
      "After dropping HasHealthcare:\n",
      "accuracy = 65.6457%\n",
      "precision = 26.5802%\n",
      "recall = 0.8042\n",
      "f1 = 0.3995\n",
      "*AUC is 0.7820\n",
      "\n",
      "After dropping NotAbleToAffordDoctor:\n",
      "accuracy = 65.6457%\n",
      "precision = 26.5802%\n",
      "recall = 0.8042\n",
      "f1 = 0.3995\n",
      "*AUC is 0.7820\n",
      "\n",
      "After dropping MentalHealth:\n",
      "accuracy = 65.6457%\n",
      "precision = 26.5802%\n",
      "recall = 0.8042\n",
      "f1 = 0.3995\n",
      "*AUC is 0.7820\n",
      "\n",
      "After dropping BiologicalSex:\n",
      "accuracy = 65.6457%\n",
      "precision = 26.5802%\n",
      "recall = 0.8042\n",
      "f1 = 0.3995\n",
      "*AUC is 0.7820\n",
      "\n",
      "After dropping AgeBracket:\n",
      "accuracy = 70.2637%\n",
      "precision = 28.4385%\n",
      "recall = 0.7203\n",
      "f1 = 0.4078\n",
      "*AUC is 0.7779\n",
      "\n",
      "After dropping EducationBracket:\n",
      "accuracy = 65.6457%\n",
      "precision = 26.5802%\n",
      "recall = 0.8042\n",
      "f1 = 0.3995\n",
      "*AUC is 0.7820\n",
      "\n",
      "After dropping Zodiac:\n",
      "accuracy = 65.6457%\n",
      "precision = 26.5802%\n",
      "recall = 0.8042\n",
      "f1 = 0.3995\n",
      "*AUC is 0.7820\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model1 = decision_tree_classification(scaled, y, 0, '')\n",
    "for i in range(len(predictors)):\n",
    "    temp = predictors[:]\n",
    "    temp.pop(i)\n",
    "    model2 = decision_tree_classification(df1[temp], y, 0,predictors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 86.1361%\n",
      "precision = 63.3484%\n",
      "recall = 0.0582\n",
      "f1 = 0.1067\n",
      "*AUC is 0.8085\n",
      "\n",
      "After dropping HighBP:\n",
      "accuracy = 86.0769%\n",
      "precision = 63.9469%\n",
      "recall = 0.0467\n",
      "f1 = 0.0871\n",
      "*AUC is 0.7971\n",
      "\n",
      "After dropping HighChol:\n",
      "accuracy = 86.1105%\n",
      "precision = 64.6953%\n",
      "recall = 0.0501\n",
      "f1 = 0.0929\n",
      "*AUC is 0.8012\n",
      "\n",
      "After dropping BMI:\n",
      "accuracy = 85.8207%\n",
      "precision = 55.2147%\n",
      "recall = 0.0125\n",
      "f1 = 0.0244\n",
      "*AUC is 0.7853\n",
      "\n",
      "After dropping Smoker:\n",
      "accuracy = 86.1499%\n",
      "precision = 63.0682%\n",
      "recall = 0.0616\n",
      "f1 = 0.1122\n",
      "*AUC is 0.8078\n",
      "\n",
      "After dropping Stroke:\n",
      "accuracy = 86.1243%\n",
      "precision = 61.6327%\n",
      "recall = 0.0628\n",
      "f1 = 0.1140\n",
      "*AUC is 0.8081\n",
      "\n",
      "After dropping Myocardial:\n",
      "accuracy = 86.0296%\n",
      "precision = 63.1130%\n",
      "recall = 0.0410\n",
      "f1 = 0.0771\n",
      "*AUC is 0.8057\n",
      "\n",
      "After dropping PhysActivity:\n",
      "accuracy = 86.1755%\n",
      "precision = 65.1772%\n",
      "recall = 0.0587\n",
      "f1 = 0.1076\n",
      "*AUC is 0.8074\n",
      "\n",
      "After dropping Fruit:\n",
      "accuracy = 86.1913%\n",
      "precision = 64.7482%\n",
      "recall = 0.0624\n",
      "f1 = 0.1138\n",
      "*AUC is 0.8085\n",
      "\n",
      "After dropping Vegetables:\n",
      "accuracy = 86.1400%\n",
      "precision = 62.8777%\n",
      "recall = 0.0606\n",
      "f1 = 0.1105\n",
      "*AUC is 0.8087\n",
      "\n",
      "After dropping HeavyDrinker:\n",
      "accuracy = 86.1794%\n",
      "precision = 63.6488%\n",
      "recall = 0.0643\n",
      "f1 = 0.1169\n",
      "*AUC is 0.8071\n",
      "\n",
      "After dropping HasHealthcare:\n",
      "accuracy = 86.1183%\n",
      "precision = 61.8644%\n",
      "recall = 0.0607\n",
      "f1 = 0.1106\n",
      "*AUC is 0.8087\n",
      "\n",
      "After dropping NotAbleToAffordDoctor:\n",
      "accuracy = 86.1735%\n",
      "precision = 62.5000%\n",
      "recall = 0.0680\n",
      "f1 = 0.1226\n",
      "*AUC is 0.8083\n",
      "\n",
      "After dropping MentalHealth:\n",
      "accuracy = 86.2504%\n",
      "precision = 65.2005%\n",
      "recall = 0.0699\n",
      "f1 = 0.1263\n",
      "*AUC is 0.8083\n",
      "\n",
      "After dropping BiologicalSex:\n",
      "accuracy = 86.1459%\n",
      "precision = 62.7451%\n",
      "recall = 0.0621\n",
      "f1 = 0.1131\n",
      "*AUC is 0.8080\n",
      "\n",
      "After dropping AgeBracket:\n",
      "accuracy = 86.1262%\n",
      "precision = 63.3540%\n",
      "recall = 0.0566\n",
      "f1 = 0.1039\n",
      "*AUC is 0.7971\n",
      "\n",
      "After dropping EducationBracket:\n",
      "accuracy = 86.1321%\n",
      "precision = 62.5179%\n",
      "recall = 0.0606\n",
      "f1 = 0.1105\n",
      "*AUC is 0.8068\n",
      "\n",
      "After dropping Zodiac:\n",
      "accuracy = 86.1597%\n",
      "precision = 64.0835%\n",
      "recall = 0.0596\n",
      "f1 = 0.1091\n",
      "*AUC is 0.8091\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model1 = random_forest_classification(scaled, y, 0, '')\n",
    "for i in range(len(predictors)):\n",
    "    temp = predictors[:]\n",
    "    temp.pop(i)\n",
    "    model2 = random_forest_classification(df1[temp], y, 0,predictors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 70.1770%\n",
      "precision = 29.2844%\n",
      "recall = 0.7763\n",
      "f1 = 0.4253\n",
      "*AUC is 0.8054\n",
      "\n",
      "After dropping HighBP:\n",
      "accuracy = 69.2171%\n",
      "precision = 28.3045%\n",
      "recall = 0.7605\n",
      "f1 = 0.4125\n",
      "*AUC is 0.7912\n",
      "\n",
      "After dropping HighChol:\n",
      "accuracy = 69.4162%\n",
      "precision = 28.6632%\n",
      "recall = 0.7737\n",
      "f1 = 0.4183\n",
      "*AUC is 0.7949\n",
      "\n",
      "After dropping BMI:\n",
      "accuracy = 68.0247%\n",
      "precision = 27.6377%\n",
      "recall = 0.7723\n",
      "f1 = 0.4071\n",
      "*AUC is 0.7811\n",
      "\n",
      "After dropping Smoker:\n",
      "accuracy = 70.1533%\n",
      "precision = 29.1373%\n",
      "recall = 0.7681\n",
      "f1 = 0.4225\n",
      "*AUC is 0.8000\n",
      "\n",
      "After dropping Stroke:\n",
      "accuracy = 70.2006%\n",
      "precision = 29.2811%\n",
      "recall = 0.7749\n",
      "f1 = 0.4250\n",
      "*AUC is 0.8044\n",
      "\n",
      "After dropping Myocardial:\n",
      "accuracy = 69.7158%\n",
      "precision = 28.9389%\n",
      "recall = 0.7769\n",
      "f1 = 0.4217\n",
      "*AUC is 0.8013\n",
      "\n",
      "After dropping PhysActivity:\n",
      "accuracy = 70.2933%\n",
      "precision = 29.2815%\n",
      "recall = 0.7704\n",
      "f1 = 0.4243\n",
      "*AUC is 0.8036\n",
      "\n",
      "After dropping Fruit:\n",
      "accuracy = 70.2361%\n",
      "precision = 29.2848%\n",
      "recall = 0.7734\n",
      "f1 = 0.4248\n",
      "*AUC is 0.8025\n",
      "\n",
      "After dropping Vegetables:\n",
      "accuracy = 70.1711%\n",
      "precision = 29.3252%\n",
      "recall = 0.7792\n",
      "f1 = 0.4261\n",
      "*AUC is 0.8037\n",
      "\n",
      "After dropping HeavyDrinker:\n",
      "accuracy = 70.1317%\n",
      "precision = 29.1730%\n",
      "recall = 0.7715\n",
      "f1 = 0.4234\n",
      "*AUC is 0.8029\n",
      "\n",
      "After dropping HasHealthcare:\n",
      "accuracy = 70.1928%\n",
      "precision = 29.2771%\n",
      "recall = 0.7751\n",
      "f1 = 0.4250\n",
      "*AUC is 0.8045\n",
      "\n",
      "After dropping NotAbleToAffordDoctor:\n",
      "accuracy = 70.3248%\n",
      "precision = 29.3932%\n",
      "recall = 0.7759\n",
      "f1 = 0.4264\n",
      "*AUC is 0.8046\n",
      "\n",
      "After dropping MentalHealth:\n",
      "accuracy = 70.2361%\n",
      "precision = 29.2652%\n",
      "recall = 0.7722\n",
      "f1 = 0.4244\n",
      "*AUC is 0.8028\n",
      "\n",
      "After dropping BiologicalSex:\n",
      "accuracy = 70.3524%\n",
      "precision = 29.3214%\n",
      "recall = 0.7699\n",
      "f1 = 0.4247\n",
      "*AUC is 0.8011\n",
      "\n",
      "After dropping AgeBracket:\n",
      "accuracy = 70.1652%\n",
      "precision = 28.7734%\n",
      "recall = 0.7450\n",
      "f1 = 0.4151\n",
      "*AUC is 0.7891\n",
      "\n",
      "After dropping EducationBracket:\n",
      "accuracy = 70.1770%\n",
      "precision = 29.2082%\n",
      "recall = 0.7715\n",
      "f1 = 0.4237\n",
      "*AUC is 0.8018\n",
      "\n",
      "After dropping Zodiac:\n",
      "accuracy = 70.1179%\n",
      "precision = 29.1710%\n",
      "recall = 0.7720\n",
      "f1 = 0.4234\n",
      "*AUC is 0.8036\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model1 = adaboost_classification(scaled, y, 0, '')\n",
    "for i in range(len(predictors)):\n",
    "    temp = predictors[:]\n",
    "    temp.pop(i)\n",
    "    model2 = adaboost_classification(df1[temp], y, 0,predictors[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Tell us something interesting about this dataset that is not already covered by the questions above and that is not obvious.\n",
    "\n",
    "After examining the correlation between each column, it was found that some columns, such as PhysicalHealth, GeneralHealth, and HardToClimbStairs, are highly correlated, which may result in double counting of factors. \n",
    "\n",
    "Additionally, some of the columns contain self-assessment data, which are known to be less reliable due to various biases and limitations compared to objective assessments or observations. For instance, a person in the dataframe who has high blood pressure, high cholesterol, smokes, lacks physical activity, does not eat fruit, and has a high BMI, but still rates their general health as \"very healthy\" (score of 5).\n",
    "\n",
    "After removing self-assessed and correlated data, the analysis was repeated and it was found that BMI was the most accurate predictor of diabetes.\n",
    "\n",
    " A possible reason for this is that BMI has a wider range of values compared to other variables which are mostly binary. For example, Age bracket has only six options. Providing more options can lead to more precise and accurate feedback by allowing respondents to better differentiate between their preferences and experiences, resulting in more detailed and nuanced feedback. This can also help capture a wider range of responses, increasing the diversity and richness of the feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "acd4db10143382ff3e6a34f783e6849722f84f848c51274ad8cd1fe1cb6afa60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
